{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NSD fMRI regression performance\\\n",
    "cliptext 1st embedding:\\\n",
    "corr: `0.9999999999999798` euclidian dist: `0.08716399866359316`\\\n",
    "clipvision 1st embedding:\\\n",
    "corr: `0.7206470311671278` euclidian dist: `0.7445045003979572`\\\n",
    "autokl:\\\n",
    "corr: `0.021463346119866764` euclidian dist: `113.58405093418304`\\\n",
    "\\\n",
    "THINGS-MEG unmodified regression performance\\\n",
    "cliptext 1st embedding: \\\n",
    "corr: `0.7132301973694442` euclidian dist: `0.6739413756833288` \\\n",
    "clipvision 1st embedding: \\\n",
    "corr: `0.6127160358947972` euclidian dist: `0.878658145980226` \\\n",
    "autokl:\\\n",
    "corr: `0.005573586983020162` euclidian dist: `114.27715624831653`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SimpleConv, BrainModule\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22248, 272, 120), (22248, 768))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array = np.load('cache/processed_data/BIGMEG1/train_thingsmeg_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "labels_array = np.load('cache/extracted_embeddings/BIGMEG1/train_cliptext1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "# labels_array = np.load('cache/extracted_embeddings/BIGMEG1/train_clipvision1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "labels_array = labels_array[:, 0]\n",
    "data_array.shape, labels_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AD/tfei/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:7')\n",
    "model = BrainModule()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: spatial_attention.weight | Number of parameters: 73440\n",
      "Layer: spatial_attention.bias | Number of parameters: 270\n",
      "Layer: linear_proj1.weight | Number of parameters: 72900\n",
      "Layer: linear_proj1.bias | Number of parameters: 270\n",
      "Layer: linear_proj2.weight | Number of parameters: 72900\n",
      "Layer: linear_proj2.bias | Number of parameters: 270\n",
      "Layer: res_dilated_conv1.0.1.weight | Number of parameters: 259200\n",
      "Layer: res_dilated_conv1.0.1.bias | Number of parameters: 320\n",
      "Layer: res_dilated_conv1.0.2.weight | Number of parameters: 320\n",
      "Layer: res_dilated_conv1.0.2.bias | Number of parameters: 320\n",
      "Layer: res_dilated_conv1.1.1.weight | Number of parameters: 307200\n",
      "Layer: res_dilated_conv1.1.1.bias | Number of parameters: 320\n",
      "Layer: res_dilated_conv1.1.2.weight | Number of parameters: 320\n",
      "Layer: res_dilated_conv1.1.2.bias | Number of parameters: 320\n",
      "Layer: res_dilated_conv1.2.1.weight | Number of parameters: 614400\n",
      "Layer: res_dilated_conv1.2.1.bias | Number of parameters: 640\n",
      "Layer: res_dilated_conv1.2.2.weight | Number of parameters: 640\n",
      "Layer: res_dilated_conv1.2.2.bias | Number of parameters: 640\n",
      "Layer: res_dilated_conv2.0.1.weight | Number of parameters: 307200\n",
      "Layer: res_dilated_conv2.0.1.bias | Number of parameters: 320\n",
      "Layer: res_dilated_conv2.0.2.weight | Number of parameters: 320\n",
      "Layer: res_dilated_conv2.0.2.bias | Number of parameters: 320\n",
      "Layer: res_dilated_conv2.1.1.weight | Number of parameters: 307200\n",
      "Layer: res_dilated_conv2.1.1.bias | Number of parameters: 320\n",
      "Layer: res_dilated_conv2.1.2.weight | Number of parameters: 320\n",
      "Layer: res_dilated_conv2.1.2.bias | Number of parameters: 320\n",
      "Layer: res_dilated_conv2.2.1.weight | Number of parameters: 614400\n",
      "Layer: res_dilated_conv2.2.1.bias | Number of parameters: 640\n",
      "Layer: res_dilated_conv2.2.2.weight | Number of parameters: 640\n",
      "Layer: res_dilated_conv2.2.2.bias | Number of parameters: 640\n",
      "Layer: linear_proj3.weight | Number of parameters: 655360\n",
      "Layer: linear_proj3.bias | Number of parameters: 2048\n",
      "Layer: mlp_proj.0.weight | Number of parameters: 2048\n",
      "Layer: mlp_proj.0.bias | Number of parameters: 2048\n",
      "Layer: mlp_proj.2.weight | Number of parameters: 1572864\n",
      "Layer: mlp_proj.2.bias | Number of parameters: 768\n",
      "Total number of parameters: 4872466\n"
     ]
    }
   ],
   "source": [
    "# Optional: see network parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Number of parameters: {param.numel()}\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 / 100, Training Loss: 0.0003109644749201834, Validation Loss: 0.00032490262549669883\n"
     ]
    }
   ],
   "source": [
    "data_tensor = torch.tensor(data_array).float()\n",
    "labels_tensor = torch.tensor(labels_array).float()\n",
    "# Create a TensorDataset from your data tensor and labels tensor\n",
    "dataset = TensorDataset(data_tensor, labels_tensor)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size  # 20% for validation\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32)\n",
    "val_dataloader = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):  # 100 epochs\n",
    "    # Training phase\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        val_loss = 0\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(val_dataloader)\n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "    clear_output(wait=False)\n",
    "    print(f'Epoch {epoch+1} / {100}, Training Loss: {loss.item()}, Validation Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr: 0.8330744653598822 euclidian dist: 0.49011951558459865\n"
     ]
    }
   ],
   "source": [
    "test_data = np.load('cache/processed_data/BIGMEG1/test_thingsmeg_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "test_labels = np.load('cache/extracted_embeddings/BIGMEG1/test_cliptext1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "# test_labels = np.load('cache/extracted_embeddings/BIGMEG1/test_clipvision1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "test_labels = test_labels[:, 0]\n",
    "\n",
    "test_data_tensor = torch.tensor(test_data).float()\n",
    "test_labels_tensor = torch.tensor(test_labels).float()\n",
    "\n",
    "test_dataset = TensorDataset(test_data_tensor, test_labels_tensor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    preds = []\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds.extend(outputs.cpu().numpy())\n",
    "    pred_labels = np.array(preds)\n",
    "# Compute the Euclidean and correlation distances\n",
    "euclidean_distances = np.array([np.linalg.norm(u - v) for u, v in zip(pred_labels, test_labels)])\n",
    "correlation_distances = np.array([correlation(u, v) for u, v in zip(pred_labels, test_labels)])\n",
    "# Compute the average Euclidean distance\n",
    "average_euclidean_distance = euclidean_distances.mean()\n",
    "correlations = (1 - correlation_distances).mean()\n",
    "print('corr:', correlations, 'euclidian dist:' ,average_euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr: 0.8331517203063764 euclidian dist: 0.4900515302499065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save pred cliptext\n",
    "# preds_array = np.array(preds)\n",
    "# preds_repeated = np.repeat(preds_array[:, np.newaxis, :], 77, axis=1)\n",
    "# # np.save('cache/predicted_embeddings/BIGMEG1/thingsmeg_dummymodule_cliptext1b_sub-BIGMEG1.npy', preds_repeated)\n",
    "\n",
    "# # save pred clipvision\n",
    "# preds_array = np.array(preds)\n",
    "# regress_labels = np.load('cache/predicted_embeddings/BIGMEG1/thingsmeg_regress_clipvision1b_sub-BIGMEG1.npy')\n",
    "# regress_labels[:, 0] = preds_array\n",
    "# # np.save('cache/predicted_embeddings/BIGMEG1/thingsmeg_dummyregress_clipvision1b_sub-BIGMEG1.npy', regress_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cliptext 1st embedding:\n",
      "corr: 0.9999999999999798 euclidian dist: 0.08716399866359316\n",
      "clipvision 1st embedding:\n",
      "corr: 0.7206470311671278 euclidian dist: 0.7445045003979572\n",
      "autokl:\n",
      "corr: 0.021463346119866764 euclidian dist: 113.58405093418304\n"
     ]
    }
   ],
   "source": [
    "# NSD fMRI regression performance\n",
    "test_labels = np.load('/mnt/sphere/projects/brain-diffuser/data/extracted_features/subj01/nsd_cliptext_test.npy', mmap_mode='r')\n",
    "test_labels = test_labels[:, 0, :]\n",
    "pred_labels = np.load('/mnt/sphere/projects/brain-diffuser/data/predicted_features/subj01/nsd_cliptext_predtest_nsdgeneral.npy', mmap_mode='r')\n",
    "pred_labels = pred_labels[:, 0, :]\n",
    "# Compute the Euclidean distances\n",
    "euclidean_distances = np.array([np.linalg.norm(u - v) for u, v in zip(pred_labels, test_labels)])\n",
    "correlation_distances = np.array([correlation(u, v) for u, v in zip(pred_labels, test_labels)])\n",
    "# Compute the average Euclidean distance\n",
    "average_euclidean_distance = euclidean_distances.mean()\n",
    "correlations = (1 - correlation_distances).mean()\n",
    "print('cliptext 1st embedding:')\n",
    "print('corr:', correlations, 'euclidian dist:', average_euclidean_distance)\n",
    "test_labels = np.load('/mnt/sphere/projects/brain-diffuser/data/extracted_features/subj01/nsd_clipvision_test.npy', mmap_mode='r')\n",
    "test_labels = test_labels[:, 0, :]\n",
    "pred_labels = np.load('/mnt/sphere/projects/brain-diffuser/data/predicted_features/subj01/nsd_clipvision_predtest_nsdgeneral.npy', mmap_mode='r')\n",
    "pred_labels = pred_labels[:, 0, :]\n",
    "# Compute the Euclidean distances\n",
    "euclidean_distances = np.array([np.linalg.norm(u - v) for u, v in zip(pred_labels, test_labels)])\n",
    "correlation_distances = np.array([correlation(u, v) for u, v in zip(pred_labels, test_labels)])\n",
    "# Compute the average Euclidean distance\n",
    "average_euclidean_distance = euclidean_distances.mean()\n",
    "correlations = (1 - correlation_distances).mean()\n",
    "print('clipvision 1st embedding:')\n",
    "print('corr:', correlations, 'euclidian dist:', average_euclidean_distance)\n",
    "test_labels = np.load('/mnt/sphere/projects/brain-diffuser/data/extracted_features/subj01/nsd_vdvae_features_31l.npz', mmap_mode='r')\n",
    "test_labels = test_labels['test_latents']\n",
    "pred_labels = np.load('/mnt/sphere/projects/brain-diffuser/data/predicted_features/subj01/nsd_vdvae_nsdgeneral_pred_sub1_31l_alpha50k.npy', mmap_mode='r')\n",
    "# Compute the Euclidean distances\n",
    "euclidean_distances = np.array([np.linalg.norm(u - v) for u, v in zip(pred_labels, test_labels)])\n",
    "correlation_distances = np.array([correlation(u, v) for u, v in zip(pred_labels, test_labels)])\n",
    "# Compute the average Euclidean distance\n",
    "average_euclidean_distance = euclidean_distances.mean()\n",
    "correlations = (1 - correlation_distances).mean()\n",
    "print('autokl:')\n",
    "print('corr:', correlations, 'euclidian dist:', average_euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cliptext 1st embedding:\n",
      "0.7132301973694442 0.6739413756833288\n",
      "clipvision 1st embedding:\n",
      "0.6127160358947972 0.878658145980226\n",
      "autokl:\n",
      "corr: 0.005573586983020162 euclidian dist: 114.27715624831653\n"
     ]
    }
   ],
   "source": [
    "# THINGS-MEG unmodified regression performance\n",
    "test_labels = np.load('cache/extracted_embeddings/BIGMEG1/test_cliptext1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "test_labels = test_labels[:, 0, :]\n",
    "pred_labels = np.load('cache/predicted_embeddings/BIGMEG1/thingsmeg_regress_cliptext1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "pred_labels = pred_labels[:, 0, :]\n",
    "# Compute the Euclidean distances\n",
    "euclidean_distances = np.array([np.linalg.norm(u - v) for u, v in zip(pred_labels, test_labels)])\n",
    "correlation_distances = np.array([correlation(u, v) for u, v in zip(pred_labels, test_labels)])\n",
    "# Compute the average Euclidean distance\n",
    "average_euclidean_distance = euclidean_distances.mean()\n",
    "correlations = (1 - correlation_distances).mean()\n",
    "print('cliptext 1st embedding:')\n",
    "print(correlations, average_euclidean_distance)\n",
    "test_labels = np.load('cache/extracted_embeddings/BIGMEG1/test_clipvision1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "test_labels = test_labels[:, 0, :]\n",
    "pred_labels = np.load('cache/predicted_embeddings/BIGMEG1/thingsmeg_regress_clipvision1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "pred_labels = pred_labels[:, 0, :]\n",
    "# Compute the Euclidean distances\n",
    "euclidean_distances = np.array([np.linalg.norm(u - v) for u, v in zip(pred_labels, test_labels)])\n",
    "correlation_distances = np.array([correlation(u, v) for u, v in zip(pred_labels, test_labels)])\n",
    "# Compute the average Euclidean distance\n",
    "average_euclidean_distance = euclidean_distances.mean()\n",
    "correlations = (1 - correlation_distances).mean()\n",
    "print('clipvision 1st embedding:')\n",
    "print(correlations, average_euclidean_distance)\n",
    "test_labels = np.load('cache/extracted_embeddings/BIGMEG1/test_autokl1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "pred_labels = np.load('cache/predicted_embeddings/BIGMEG1/thingsmeg_regress_autokl1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "# Compute the Euclidean distances\n",
    "euclidean_distances = np.array([np.linalg.norm(u - v) for u, v in zip(pred_labels, test_labels)])\n",
    "correlation_distances = np.array([correlation(u, v) for u, v in zip(pred_labels, test_labels)])\n",
    "# Compute the average Euclidean distance\n",
    "average_euclidean_distance = euclidean_distances.mean()\n",
    "correlations = (1 - correlation_distances).mean()\n",
    "print('autokl:')\n",
    "print('corr:', correlations, 'euclidian dist:', average_euclidean_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
