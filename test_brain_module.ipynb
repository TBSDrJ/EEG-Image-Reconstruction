{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SimpleConv, BrainModule\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AD/tfei/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:7')\n",
    "model = BrainModule()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: spatial_attention.weight | Number of parameters: 220320\n",
      "Layer: spatial_attention.bias | Number of parameters: 270\n",
      "Layer: linear_proj1.weight | Number of parameters: 218700\n",
      "Layer: linear_proj1.bias | Number of parameters: 270\n",
      "Layer: linear_proj2.weight | Number of parameters: 218700\n",
      "Layer: linear_proj2.bias | Number of parameters: 270\n",
      "Layer: res_dilated_conv1.weight | Number of parameters: 259200\n",
      "Layer: res_dilated_conv1.bias | Number of parameters: 320\n",
      "Layer: res_dilated_conv2.weight | Number of parameters: 307200\n",
      "Layer: res_dilated_conv2.bias | Number of parameters: 320\n",
      "Layer: linear_proj3.weight | Number of parameters: 1966080\n",
      "Layer: linear_proj3.bias | Number of parameters: 2048\n",
      "Layer: mlp_proj.weight | Number of parameters: 1572864\n",
      "Layer: mlp_proj.bias | Number of parameters: 768\n",
      "Total number of parameters: 4767330\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Number of parameters: {param.numel()}\")\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22248, 272, 120), (22248, 768))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array = np.load('cache/processed_data/BIGMEG1/train_thingsmeg_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "labels_array = np.load('cache/extracted_embeddings/BIGMEG1/train_cliptext1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "labels_array = labels_array[:, 0]\n",
    "data_array.shape, labels_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your data array is named 'data_array' and your labels array is named 'labels_array'\n",
    "data_tensor = torch.tensor(data_array).float()\n",
    "labels_tensor = torch.tensor(labels_array).float()\n",
    "\n",
    "# Create a TensorDataset from your data tensor and labels tensor\n",
    "dataset = TensorDataset(data_tensor, labels_tensor)\n",
    "\n",
    "# Create a DataLoader from your TensorDataset\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True) # original batch size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 / 150, Training Loss: 0.0002957053657155484, Validation Loss: 0.00032479986340539266\n"
     ]
    }
   ],
   "source": [
    "# Assuming total_data is your total dataset\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size  # 20% for validation\n",
    "\n",
    "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32)\n",
    "val_dataloader = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(150):  # 100 epochs\n",
    "    # Training phase\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        val_loss = 0\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "        val_loss /= len(val_dataloader)\n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "    clear_output(wait=False)\n",
    "    print(f'Epoch {epoch+1} / {150}, Training Loss: {loss.item()}, Validation Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.00032319269479817844"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load('cache/processed_data/BIGMEG1/test_thingsmeg_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "test_labels = np.load('cache/extracted_embeddings/BIGMEG1/test_cliptext1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "test_labels = test_labels[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tensor = torch.tensor(test_data).float()\n",
    "test_labels_tensor = torch.tensor(test_labels).float()\n",
    "\n",
    "test_dataset = TensorDataset(test_data_tensor, test_labels_tensor)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average correlation between predicted and test labels: 0.8405434170403377\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds.extend(outputs.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "    correlation_matrix = np.corrcoef(preds, true_labels)\n",
    "    avg_correlation = np.mean(correlation_matrix)\n",
    "    print(f'Average correlation between predicted and test labels: {avg_correlation}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.840537235832449\n",
    "# 0.8405433424275223\n",
    "# 0.8405434170403377"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 / 86, Loss: 0.0004975283518433571\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(22248//256):  # 100 epochs\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    clear_output(wait=False)\n",
    "    print(f'Epoch {epoch+1} / {22248//256}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(preds).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_array = np.array(preds)\n",
    "preds_repeated = np.repeat(preds_array[:, np.newaxis, :], 77, axis=1)\n",
    "test_labels = np.load('cache/extracted_embeddings/BIGMEG1/test_cliptext1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "# np.save('cache/predicted_embeddings/BIGMEG1/thingsmeg_dummymodule_cliptext1b_sub-BIGMEG1.npy', preds_repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 77, 768)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y has more than 2 dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m regression_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcache/predicted_embeddings/BIGMEG1/thingsmeg_regress_cliptext1b_sub-BIGMEG1.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, mmap_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m regression_labels \u001b[38;5;241m=\u001b[39m regression_labels[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrcoef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregression_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:2846\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   2842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;129;01mor\u001b[39;00m ddof \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[1;32m   2843\u001b[0m     \u001b[38;5;66;03m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[1;32m   2844\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias and ddof have no effect and are deprecated\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   2845\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m-> 2846\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2847\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2848\u001b[0m     d \u001b[38;5;241m=\u001b[39m diag(c)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/function_base.py:2623\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2621\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y)\n\u001b[1;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 2623\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my has more than 2 dimensions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2626\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: y has more than 2 dimensions"
     ]
    }
   ],
   "source": [
    "regression_labels = np.load('cache/predicted_embeddings/BIGMEG1/thingsmeg_regress_cliptext1b_sub-BIGMEG1.npy', mmap_mode='r')\n",
    "regression_labels = regression_labels[:, 0]\n",
    "np.corrcoef(regression_labels, test_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.ones((1000, 272, 120))\n",
    "labels_array = np.ones((1000, 768)) + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your data array is named 'data_array' and your labels array is named 'labels_array'\n",
    "data_tensor = torch.tensor(data_array).float()\n",
    "labels_tensor = torch.tensor(labels_array).float()\n",
    "\n",
    "# Create a TensorDataset from your data tensor and labels tensor\n",
    "dataset = TensorDataset(data_tensor, labels_tensor)\n",
    "\n",
    "# Create a DataLoader from your TensorDataset\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625 / 625, Loss: 1.325312970479331e-09\n"
     ]
    }
   ],
   "source": [
    "# pbar = tqdm(total=100, desc='Epoch: ')\n",
    "# Training loop\n",
    "for epoch in range(20000//32):  # 100 epochs\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    clear_output(wait=False)\n",
    "    print(f'Epoch {epoch+1} / {20000//32}, Loss: {loss.item()}')\n",
    "    # torch.cuda.synchronize()\n",
    "    # pbar.set_postfix(Loss=loss.item())\n",
    "    # pbar.update()\n",
    "    # pbar.refresh()\n",
    "# pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.0001, device='cuda:7', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.ones(272,120).to('cuda:7')).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = {'meg': 272}\n",
    "model_chout = 768\n",
    "n_subjects = 1\n",
    "# args_simpleconv = {'concatenate': False, 'depth': 10, 'linear_out': False, 'complex_out': True, 'kernel_size': 3, 'dilation_growth': 2, 'dilation_period': 5, 'skip': True, 'post_skip': False, 'growth': 1.0, 'scale': None, 'rewrite': False, 'groups': 1, 'glu': 2, 'glu_context': 1, 'glu_glu': True, 'gelu': True, 'dual_path': 0, 'conv_dropout': 0.0, 'dropout_input': 0.0, 'batch_norm': True, 'relu_leakiness': 0.0, 'subject_dim': 0, 'subject_layers': True, 'embedding_scale': 1.0, 'subject_layers_dim': 'input', 'subject_layers_id': False, 'n_fft': None, 'fft_complex': True, 'merger': True, 'merger_pos_dim': 2048, 'merger_channels': 270, 'merger_dropout': 0.2, 'merger_penalty': 0.0, 'merger_per_subject': False, 'dropout': 0.0, 'dropout_rescale': True, 'initial_linear': 270, 'initial_depth': 1, 'initial_nonlin': False, 'hidden': {'meg': 320}}\n",
    "args_simpleconv = {'concatenate': False, 'depth': 10, 'linear_out': False, 'complex_out': True, 'kernel_size': 3, 'dilation_growth': 2, 'dilation_period': 5, 'skip': True, 'post_skip': False, 'growth': 1.0, 'scale': None, 'rewrite': False, 'groups': 1, 'glu': 2, 'glu_context': 1, 'glu_glu': True, 'gelu': True, 'dual_path': 0, 'conv_dropout': 0.0, 'dropout_input': 0.0, 'batch_norm': True, 'relu_leakiness': 0.0, 'subject_dim': 0, 'subject_layers': False, 'embedding_scale': 1.0, 'subject_layers_dim': 'input', 'subject_layers_id': False, 'n_fft': None, 'fft_complex': True, 'merger': True, 'merger_pos_dim': 2048, 'merger_channels': 270, 'merger_dropout': 0.2, 'merger_penalty': 0.0, 'merger_per_subject': False, 'dropout': 0.0, 'dropout_rescale': True, 'initial_linear': 270, 'initial_depth': 1, 'initial_nonlin': False, 'hidden': {'meg': 320}}\n",
    "subjects = torch.tensor([1]) # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleconv = SimpleConv(in_channels=in_channels, out_channels=model_chout,\n",
    "                           n_subjects=n_subjects, **args_simpleconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleConv(\n",
       "  (merger): ChannelMerger(\n",
       "    (embedding): FourierEmb()\n",
       "  )\n",
       "  (initial_linear): Sequential(\n",
       "    (0): Conv1d(270, 270, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (agg_layer): AdaptiveAvgPool1d(output_size=1)\n",
       "  (mlp_head_clip): Sequential(\n",
       "    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "  )\n",
       "  (mlp_head_mse): Sequential(\n",
       "    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=1024, out_features=768, bias=True)\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): Conv1d(320, 640, kernel_size=(1,), stride=(1,))\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): ConvTranspose1d(640, 768, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (encoders): ModuleDict(\n",
       "    (meg): ConvSequence(\n",
       "      (sequence): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv1d(270, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(4,), dilation=(4,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (8): Sequential(\n",
       "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(8,), dilation=(8,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (9): Sequential(\n",
       "          (0): Conv1d(320, 320, kernel_size=(3,), stride=(1,), padding=(16,), dilation=(16,))\n",
       "          (1): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "      (glus): ModuleList(\n",
       "        (0): None\n",
       "        (1): Sequential(\n",
       "          (0): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): GLU(dim=1)\n",
       "        )\n",
       "        (2): None\n",
       "        (3): Sequential(\n",
       "          (0): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): GLU(dim=1)\n",
       "        )\n",
       "        (4): None\n",
       "        (5): Sequential(\n",
       "          (0): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): GLU(dim=1)\n",
       "        )\n",
       "        (6): None\n",
       "        (7): Sequential(\n",
       "          (0): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): GLU(dim=1)\n",
       "        )\n",
       "        (8): None\n",
       "        (9): Sequential(\n",
       "          (0): Conv1d(320, 640, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): GLU(dim=1)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpleconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb9af4b37f0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABvmUlEQVR4nO3deXgU9f0H8PfsbnZzXwQSAuFG7juQRK22FQWxrVZr0WJFpFitWi3WFmwrtlaxaq23/jyqtt5a8aqiFG/NwRVuEOQUSCCE3Mle8/39sdndmd2ZPZLdHMP79Tx5nuzuHN/ZY+Yzn+8lCSEEiIiIiAzG1N0FICIiIooHBjlERERkSAxyiIiIyJAY5BAREZEhMcghIiIiQ2KQQ0RERIbEIIeIiIgMiUEOERERGZKluwsQa7Is4/Dhw0hLS4MkSd1dHCIiIoqAEAKNjY3Iz8+HyRSbHIzhgpzDhw+joKCgu4tBREREHXDw4EEMHDgwJtsyXJCTlpYGwPMmpaend3NpiIiIKBINDQ0oKCjwXcdjwXBBjreKKj09nUEOERFRLxPLpiZseExERESGxCCHiIiIDIlBDhERERkSgxwiIiIyJAY5REREZEgMcoiIiMiQGOQQERGRITHIISIiIkNikENERESGxCCHiIiIDIlBDhERERkSgxwiIiIyJAY5RERRqK89hrJ//QlVB3d3d1GIKAwGOUREUdjz1OUo3vMgxNOzu7soRBQGgxwioiiMaV4DAOiPY91cEiIKh0EOERERGRKDHCIiIjIkBjlERERkSAxyiIiIyJAY5BARRUFA6u4iEFGEGOQQERGRITHIISIiIkNikENERESGxCCHiIiIDIlBDhERERkSgxwiIiIyJAY5REREZEgMcoiIiMiQGOQQERGRITHIISKKAkc8Juo9GOQQERGRITHIISIiIkNikENERESGxCCHiIiIDIlBDhERERkSgxwiIiIyJAY5REREZEgMcoiIiMiQGOQQERGRIXVJkPPII49gyJAhSExMRFFRESoqKnSXfeONN1BYWIjMzEykpKRg8uTJ+Pe//90VxSQiIiIDiXuQ88orr2Dx4sVYtmwZ1q9fj0mTJmHWrFk4evSo5vLZ2dn4wx/+gNLSUmzatAkLFizAggUL8MEHH8S7qERERGQgkhBCxHMHRUVFmD59Oh5++GEAgCzLKCgowPXXX48lS5ZEtI2pU6fivPPOw+233x522YaGBmRkZKC+vh7p6emdKjsRUaCWZf2QLNk9D26r797CEBlIPK7fcc3kOBwOrFu3DjNnzvTv0GTCzJkzUVpaGnZ9IQRWr16NnTt34owzztBcxm63o6GhQfVHREREFNcgp6amBm63G7m5uarnc3NzUVVVpbtefX09UlNTYbVacd555+Ghhx7C2Wefrbns8uXLkZGR4fsrKCiI6TEQERFR79Qje1elpaWhsrISa9aswR133IHFixfjk08+0Vx26dKlqK+v9/0dPHiwawtLREREPZIlnhvPycmB2WxGdXW16vnq6mrk5eXprmcymTBixAgAwOTJk7F9+3YsX74c3/3ud4OWtdlssNlsMS03ERER9X5xzeRYrVZMmzYNq1ev9j0nyzJWr16NkpKSiLcjyzLsdns8ikhEREQGFddMDgAsXrwY8+fPR2FhIWbMmIH7778fzc3NWLBgAQDg8ssvx4ABA7B8+XIAnjY2hYWFGD58OOx2O9577z38+9//xmOPPRbvohIREZGBxD3ImTt3Lo4dO4Zbb70VVVVVmDx5MlauXOlrjHzgwAGYTP6EUnNzM371q1/h22+/RVJSEkaPHo3nn38ec+fOjXdRiYiIyEDiPk5OV+M4OUQUTxwnhyg+et04OURERETdhUEOERERGRKDHCIiIjIkBjlERERkSAxyiIiIyJAY5BAREZEhMcghIiIiQ2KQQ0RERIbEIIeIKAoCUncXgYgixCCHiIiIDIlBDhERERkSgxwiIiIyJAY5REREZEgMcoiIiMiQGOQQERGRITHIISIiIkNikENERESGxCCHiCgKHAyQqPdgkENERESGxCCHiIiIDIlBDhERERkSgxwiIiIyJAY5REREZEgMcoiIiMiQGOQQERGRITHIISIiIkNikENERESGxCCHiCgKorsLQEQRY5BDREREhsQgh4iIiAyJQQ4REREZEoMcIiIiMiQGOURERGRIDHKIiIjIkBjkEBFFQeruAhBRxBjkEBERkSF1SZDzyCOPYMiQIUhMTERRUREqKip0l33yySfxne98B1lZWcjKysLMmTNDLk9ERESkJe5BziuvvILFixdj2bJlWL9+PSZNmoRZs2bh6NGjmst/8sknuPTSS/Hxxx+jtLQUBQUFOOecc3Do0KF4F5WIKCyOeEzUe0hCiLj+ZouKijB9+nQ8/PDDAABZllFQUIDrr78eS5YsCbu+2+1GVlYWHn74YVx++eVhl29oaEBGRgbq6+uRnp7e6fITESk1LstDmtTqeXBbffcWhshA4nH9jmsmx+FwYN26dZg5c6Z/hyYTZs6cidLS0oi20dLSAqfTiezs7HgVk4iIiAzIEs+N19TUwO12Izc3V/V8bm4uduzYEdE2fv/73yM/P18VKCnZ7XbY7Xbf44aGho4XmIiIiAyjR/euuuuuu/Dyyy9jxYoVSExM1Fxm+fLlyMjI8P0VFBR0cSmJiIioJ4prkJOTkwOz2Yzq6mrV89XV1cjLywu57r333ou77roLH374ISZOnKi73NKlS1FfX+/7O3jwYEzKTkRERL1bXIMcq9WKadOmYfXq1b7nZFnG6tWrUVJSorve3Xffjdtvvx0rV65EYWFhyH3YbDakp6er/oiIiIji2iYHABYvXoz58+ejsLAQM2bMwP3334/m5mYsWLAAAHD55ZdjwIABWL58OQDgb3/7G2699Va8+OKLGDJkCKqqqgAAqampSE1NjXdxiYiIyCDiHuTMnTsXx44dw6233oqqqipMnjwZK1eu9DVGPnDgAEwmf0Lpscceg8PhwE9+8hPVdpYtW4bbbrst3sUlIiIig4j7ODldjePkEFE8NdzWH+lo8TzgODlEMdPrxskhIiIi6i4McoiIiMiQGOQQERGRITHIISIiIkNikENERESGxCCHiIiIDIlBDhERERkSgxwiIiIyJAY5REREZEgMcoiIoiJ1dwGIKEIMcoiIiMiQGOQQERGRITHIISIiIkNikENERESGxCCHiIiIDIlBDhERERkSgxwiIiIyJAY5REREZEgMcoiIoiC6uwBEFDEGOURERGRIDHKIiIjIkBjkEBF1kJDl7i4CEYXAIIeIqIOEYAsdop6MQQ4RUQcxyCHq2RjkEBF1kBCsriLqyRjkEBF1EDM5RD0bgxwiog5ikEPUszHIISLqIFZXEfVsDHKIiKIgIPn/ZyaHqEdjkENE1FEMcoh6NAY5REQdxEwOUc/GIIeIqIPYJoeoZ2OQQ0TUQczkEPVsDHKIiDqIQQ5Rz8Ygh4goChL8gQ2DHKKejUEOEVEHMcgh6tkY5BARdRCDHKKerUuCnEceeQRDhgxBYmIiioqKUFFRobvs1q1bcdFFF2HIkCGQJAn3339/VxSRiCh6DHKIerS4BzmvvPIKFi9ejGXLlmH9+vWYNGkSZs2ahaNHj2ou39LSgmHDhuGuu+5CXl5evItHRBQV5YjHYBdyoh4t7kHOfffdh0WLFmHBggUYO3YsHn/8cSQnJ+Of//yn5vLTp0/HPffcg0suuQQ2my3exSMi6jBWVxH1bHENchwOB9atW4eZM2f6d2gyYebMmSgtLY3JPux2OxoaGlR/RERdgUEOUc8W1yCnpqYGbrcbubm5qudzc3NRVVUVk30sX74cGRkZvr+CgoKYbJeIKByOeEzUs/X63lVLly5FfX297+/gwYPdXSQiOkkwk0PUs1niufGcnByYzWZUV1ernq+uro5Zo2Kbzca2O0TUZZSDARJRzxbXTI7VasW0adOwevVq33OyLGP16tUoKSmJ566JiOJC0beKmRyiHi6umRwAWLx4MebPn4/CwkLMmDED999/P5qbm7FgwQIAwOWXX44BAwZg+fLlADyNlbdt2+b7/9ChQ6isrERqaipGjBgR7+ISEYUhdP4nop4m7kHO3LlzcezYMdx6662oqqrC5MmTsXLlSl9j5AMHDsBk8ieUDh8+jClTpvge33vvvbj33ntx5pln4pNPPol3cYmIIiczyCHqySRhsHxrQ0MDMjIyUF9fj/T09O4uDhEZTOOyPKRJrQCAY1dtRN/8Id1bICKDiMf1u9f3riIi6kpsk0PUezDIISKKgrJ3FcfJIerZGOR0ktvl6u4iEFEXUgc5zOQQ9WQMcjphR/mHsN+ej/LX/t7dRSGi7sAgh6hHY5DTCdnv/xLJkh1FW//S3UUhoi7C6iqi3oNBDhFRFNRBTjcWhIjCYpDTCULVz4KITgaqXz2jHKIejUFOJzDIITr5xLrhcaw7L5S/vBxr3no0ptsk6q0Y5HRK5EFOQ91xHNy9OY5loUgcO7wPa99+DA57W5fvu/yVu7B+5bNdvl+Kp861ySl/eTlabx+Ir9d/EpPSHN63E0U77sL0DUtjsj2i3o5BTidEdQ93/3gUPH869u9YH6/iUCSe+C4K1y/BuheXdelu9++sRNH25ZhadkOX7pc87G0tMdyaIpPTyWkdinbchVSpFbZ3r+tsoQAAzXVHff8LmY2ie6t17z2Dw38+Bbs3ftHdRfFxu1zYt31tr/teMcjpIunwnGSPrH/P95zsdmP/zspe96XpzfriBACgz6GPol5XdruxrWwlmhvrol63+URV1OtQbGz86GXY7uqPspfuiMn2VCMex2iCzli17BGy2/e/3A3nlbaWJpQ+/dsedXHujaZV3Ih8UY3kN6+Mar2qg7tR9uhVOLRne8zLtPaxhRjyylkoe75rbxA7i0FOJwipA2+f5D9FVjzxKwx+6UyUPcfUcleTOnBZWfPa3Ri7ci6+fWBWp/bNASRjp+bwfuza8FnIZYZ/eiMAoHjn3THZp+q708O6kMuqIMcdYsn42PDSMpQcfBIjVpzX5fs2IquwR7V843OXoPjoKzD964cxL0vR8TcBANO+eSTm244nBjmd0JG7L0kRGBVXvwwAKNn/OADA5XRgy+dvoaWpPhbFM5zqb7/Buvee7rYgIWfXqwCAUa4dUa8rKYJbpzO6Exfpy3liIka+9UN8s7lMdxkzYnuxj8+IxzHqxODu3iAnuYbtDmMp2puxka5dAID+OBaP4gAA5F4WNvSu0vYwHepdJemvs/a5JRi/+nJ889AFHS+UgaU9WYJpFYux9j/dM8J0Z3rTSYp1nQ4GObFWs+0T3dfMnWwcHEg9QWdMN91pysCmo9Xgnak+lzqZ2WptbuzU+kbTkYxzvDHIOalEdtGTFXdXCFHFNerb1wAAE+xsnKwlWfIEB9b9n3R+Y914dXIxyIkD/d9irDM5JqnnVlcpAxS3O/qMZ0PdcRy5fTTKH17Qof1LouPvdem//oSkewZi08evd3gbRtMTBylhkHMSifTO3uFQdlfWX6fnxeyk1JlMjvIO28XqqtgLkSE1S3H8ZcUoWI7muyVkGRUPXoayF/6s8Zo/sOlIw+Ptq55BvqhGUc0bUa8LAFInsmYlex4EAOR/elOHt2E80X2/nMIcp3L4yR1pi9qNeldpeynVmCwhviAcXLDrZLhrsfOvRahY8RCACNPkIS6k4cguh+//kzXI2b3xC+yq/LxD6zY1nMCuys/1q1K66MQbuP9Y9a4Kp6WpHjsqVkF2u7FjzSrMqH0Hxbvu0yhf53pXSRZbp8rZ2eoqAEgSXT+GVVdyOR1wOR3hF+yArsiyuHtZ2NC7SttLOe2tcdt27dFDKHt+GWqqDsZtH0bUD7UY5dqBGRv/iG2l7yPpnoEo/b/r47Y/2eX0/R+vE1xP1tbajBErzsPIN3/QoXYXx+4/EyPf/AEq//ei7zl1A/SuuUEIbGgcu4bHoe156EcY/d5PsOb1e+BS3DQFBl2qNjkdqK4y21J9/7e1NEW9fkyCHBj3JkB2u7H/rhk4tHxqRB0oom2ToxeAbCt9H5V3z8bhfTuj2p4WVledRCJN26mCHNmpu1xHMjlHnroUxbvvx/GnfuJ7bs0bD2DD3eeyEV+EElb/CQBQcuRfIZfrVHWV2/+5u0/CTE5rU4Pv/46MMzRU3u/5Z+NLADwXC4fidyUFZNnaWprQWF8bfUGjFbM2OaG/W+PtlQCAvJ3Pw5xg9T2vrgoPzORE3z7GbE30/d9YVxP1+p2prvJStnk6sn9nyJ5zkSp/5W849OdTcGjP1k5vqzMa62ow3L0Xg+WDOHZkX9jlow1yXJJ2ddXYDy7B5JZS1L24MKrtaeltNQ4Mcjolsg/bqTgRCVds7+LHOTYCUHdrnr7pVkxp+QobV9wb032dLMpevB2Vd8+O6dQPwu3/3I989RLW3Xt+11yEewh1I9jgE/fujV9g61fvBT0fSJJdqK89huO3D8f2x36meEH9W5T/Ngxp/xjaoWxEKMGZnJhuPsihPduxefn3fI/NwgWTIshpC7iRUWZvOlJdJSvWb66PPMipqTqI9SufhVnEdniH/s/MwPD/zEL1t990ajtF2+/EAFGNY69H395n77Y12P+X8Vj//jOdKgOgHnm7raku7PLRhhNuhG6Tk+M4FOUWgzGTcxKJ9PzmUgY5bv1MTqyJ5ujvxLrKoT3bdTNNmz5+Hbtun4Y9W8q7uFQexV/fi8ktpah87wnV853K5Ciqq0oOPoVpTZ9gy6t/6fD2ehvlb0Crum7EivMw7sNLUVN1IOR2TMKF7e8/ir44galN/kEAVb2KXC5fT7wje7Xv3O1tLdj51yKUPbooquMQAZmbY9s+w67bp2FH+YdRbSdouzrPN794uaq3pVm4VMMRtLWqgzjl90x0IJMjXP4sY2vD8YjXcz3+PUwtuwGnuL4Ou+yOtaux+/ap2Fb6fuiyKD7T6t2VEZclFLM7+hsX+T+LMFg+iKnlN3Z6//YWf0azJYogUmn/zkocr/5W87VwAUgsuqTLYQKpnoZBThdwKaur3F3XHkOK8jZzW+n7qHjgZ6iv7dhAUhUPzEPrsr4oe/62kMvt3vgFBvyrGLX3TtN8feKnCzHSvRvW/1zeoXLoiXb8D7m1IeCZjgc5WsGtqU2dyamrqcK2O09H+WsdGweo7NGrUPHAvA6tG2/KbGZgdZ1yiIXaw3tDbsckXIDJEvyCohpYVY1l0j4h7yx7H6NcO1B89FX1EA8A6muPBT3nFZjJKdr2V4x078Yp7/00ZLnD0ftmDXCqgz4z3KpsjSMgyFFmDMNVV9Uc3o/S/7seh/f6s8DK76m9UT/T6Ha5UP7QfKx50zP6bV4Ug88Ne+enGOH+BmM/uES9TeF/Fw7v3YGKV//mfzFGKbNoL/LV336DDPcJ32O970Ug2e3WPN/YFZlFe0MkQY66vEf278Tgl85En8fGaS4dLpMTkyCHvauMa++2NVj39x/j4K6N7c8En5pcTgfW3/MDlD79W99zbmW9ueIkpPxRA3Go6wzTXsDe1oJ1956Piv/cD8BTbzvjxH+x898dm0RyQu2HSJIcKN79j5DLHSt7BQAwQFQD8JzQtKqGMuTYjvzsjLrBb+zqImSNIEeYrKrHu56/EWMdm1G0NfoMj8PehuKjr2DGiXdj0rgw1tSZHPV7oR4BOvR7bpadmoGLshpY+V2SdH5T1pQM3//KthH7tq9FxoMjsPHvP9BcT6+hsSlO3dRTJPXvwgy3qurP3hIY5CgzOaF//9XPzvO0Q1NMAaB8H51N+pmcbV+9g6Ljb2J65S1oqAud8ak/Xo31K5+Fw96GhrrjsEraVVrNUpLv/5xnT0PRjrv85YpjL7bArPKhPVtR/tB8bPnibeQ+NRU5qPO91nT7QNU0Ii6nAxs+eE7V8cPldGD/HVOx9W+easYNHzyHHWv+BwBwtvk/L2dj+CAn8Eb1yLavQi4fLssSm0xO7wobNG6JSE/OKz/EUKkVh1/cgnWp4zFNDk6tb/vibUxt/hxo/hxCvhuSyQSXUyfIgRlm+H/wsQhyhCz7txImyKl8+2EUNX0CbP4EuOhG3/OZjbs6tG/lyLIupwOWBKvmcsoBw3Zv/BIjVszB2vSzUbg4voOAOeyt0CqR7vse2P6iM5kcl0aQE9Bdd0D9Os11W5rqsemdhzH41J+g/+BRmsu4nHbfscWzN19HuUJkcpwOO7zvRLjsg1k4NTM5you7qg2c3kldEQDUHNiJ3IHDAQDVqx/FEABTWrQvJoHVVbES6aXHApfqWF1tzertKF4Ll3UY5/BMwZAv/DOXqxrIt5wIWse3X0WWc8fHL2JGiP0cfvzHmOrcitID65BX9SnSdZZrQ6JvIuPAQEjuYGN9e1sLbInJvseBQcM3m77C8DfOxRH0RdJtuwEA4t8XokhUAf97M2h76WhB7Tu/AqZsAQCsfe1vKP76XlSX9gFu2wMAOPj1BgyV9wF2YOfajzCl9NeelafXw6nIvMkt4dvkBZ5xwiW03JIp5JfJFGWQU3+8GharDUnJab7QhpkcA0uTPBePfHEU0xq1Z7F2KO5+GtoblipP6pJisK54jDeg7m0R+gstN2vfgVnk8BmPbaXvo3LVi6oTab2U5vv/6CH9agdrk/+up26/50Sb1hLcBd77A4/VNAhOnYbE+t1eY3j3qNWrzpKoeqi82ChtfOGPKN55N1Ke+Z7m6wDgdCiqKbqw3Vek3CGCHNUI0GHO4ibhhqRVXaW4eVAGVENeOUu7PIqgs6XKH9TL1pSQ++9Ml/Gy55eh/OEFnZo2wSLcqsbBTrt+kLP/s3+h6oD+DYtDaASLikxO8df3ArdloPy14A4MziZ/AORuqNLcvreL9Binp13UmMNv+HvJaWgzJem+5m4L3VP0m01fYfNnb6meK/vXn2BZno9tZSsVz6o/v6MVnlHmlXM9DRTax+OVJPsbD6ft87TFyoX/XKr8itRu/K9qXbfdH+SIEEGkvtDfHWUmR6uLemDvNyHLKHv8V6i4/1LUHFZ/NnU1Vch46BQc+8fpqgbTopeFDb2rtL2Aq9F/oaqr8nxplCf44uqX0dTg+XKHqz+Nhtxe9dXW6v8ySjp3xRs+fB7fbNJPeyaI0EHOiWNHMHrlpZj85TWoeGW573mT4gd04tBuzXXXvv24qsGo90dv0uiVYYKMsueXwXXHQOxcqx1UBmqsr9UNsPQG4VMer+oCFJjJ6cBggDvXfoRdGz7TbnCuyOQoe4+0CnW+KatmLQAgHf4Lmux2Y8Pd56LssasBqI9Ndjnhdrkibj+gFNgYvLG+FjvuKNEcXRfwNCJdf88PfO069HqMKbOZQUGO4sIqa2S8lMzCBckcOshxOvQbl3pP/LIyKKpTNOJUBDlClrGj/EOUPvFr2NtaPMF2mCCnvvYYSp/4NfZvD87KFe++H0U1b6D6LyNR9vwy1WuB363SZ5fg2z8HZ+0scEPIkWVySvY+gj5PF/kef7O5DOUP/hzHDu8DADi1EvkawXjR1tuDF1NmIXTaGa59dAG+/fNo3+NkETrD6JT0ByJ0t4XuJTf8jXMx4aPLVVW1xXsehFkSSPnwt4ol1Z+fXnVmKIloQ/lrf8e+v0xAqiv4++5y+I/TVquuOnbb/ednc1skmZyA71uI75+QZaQI//vU1tqE0uduQdnjv/I9F5jJObBzA4qrXsCMuvew64NHVa/t+uI/AIAh8kE4VEEOu5Cf3Or9XfQaazwnT9mlPulueWEpgPbUYoy42gMmZUNESXZAdrtRseJB7N9ZCcBzopvy1bUY/sa5uj8YrSBHyDLqajx3OI0nqv1tEOr9GRiLoupt8IcLNe9YB66/R73d9iBHr+tp8e77kSQ5IH/wR83XAU/Q5T0+8Y/x6PfkZNQeDe4qqZfJSRD+i65LdZENfH/8P+5I7sabGk5g1Ls/xsi3fgjhaA56XTIn+P7fX/6O7/9WSZ3haU3IDFp3z5ZSTGn5CsXVL8Fhb1MFOY7WRhy4cxq+vuv0qLIGFSseRNI9A7HmzYd9z215816Mdm7THF0XAEa/eyGmNn+OxhcuR+n/XY+0fwzF5s9WAADWv/+Mry2CrMjWuAPaRikzOcNX/hxlLwZfVL3McIXN5IQah2j7PZ7MjiqYUgRgkiLIaW6qx+j3L0bJ4eew44HzId8xAJWv3qm7bQD4+rlrUXL4OQx82Z9B2rd9rSr4y0MNinffHzIILdn3mGZGwQIXZMUdujsgk4OAYDpB8u9j+H9moaj2bVQ/Nx8A4JRCZ3JCUWUhXNq/q6LatzFQHPE9tkqhg+5QAwlq/X68lJnehurgTJEyuxFU/dOBG5ckYUfR1r9giHwAg+XgXk4ORQ+qvi3+mxchy6rPK8FRF3ZfEgS+Xv8pyh9ZiPoTNarq0sDfdsUjVyAb/n23NjeiZO8jKK56wb+9gPe4rdnf7lFqUWf2XUf9DdJbm5WdMHrXBEQMcmLM2uy/uLbWev4XASfd1LrtAIIzOZ2JkL1BjrIhosnVinXvPI4ZG/+EwS+dCQBoOKy4s9A5qdgQfKIr/79rkPnwKGz8+DV19Zvi4mJRtLVJlVoDAob2MgWmS9tPXqb2SRS9mYlATnOy5vMAgEemY/BLZ2Lf9rW+bMfhr4PvpPXu8K1CJwsQ4q4pkkbMTcrB1AIvRlDfdbsVwXGCCGiYa8v2/e+9MEqKAPnowd1wKxrzNuzfhKHyPox2bgsaLC6UGRs9gyJOr/yD/0lHi87SavnOA77BFNM+uRV7t63B1PIbMfq/FwEA3IpAQlZ0U5bdbtQpLkw2yempJtFhFi7AHJwBlZTtVEIcs3dQPeU0G5KyW7FiMLWGWn9WdlJrhads+x7R3TYA9G/wdErwzpe15Yu3MeSVs9B4f1HQsoHdvyNhloR6fqqAzyeSISoG2D1tR5xIUD2/d9salOx9WGuV4HLY/UGOFKMeo4HnBqVQQY5y0EJLYnB141B5n2JD+jcukdJrOO3lUnyuBeKw/3mXU3UcVqe6Y0XFf+4PqnIDgFPe/hGKjr2Onc9dryp/4DhIRcfV6zbXBfd4C8zkKH8rZoe6N2linT9Aa2nwB+mWGI+FFG8McmLEe/FJdPh//K46z4VLdqpPum4pAeWv/V0VdQtZVgU55Q8v0K0iADzVAhvvmunfV/tdmUORvja7WiB/u1a1niXJ3+xPsmv3XrJqZHKKq18GAKR9/lfVnbf3BFdzeH9QTxCHRgPYwBmhpfYfvbk9QCqufsn/muIHObFtjWZZ9+9Yjyx4qliOfOm/Y0lITA1aVu8O3wplkKM49hANj0NViXgp79RNTo0LmnKAPMV3xAb1hUq2+XsC1R7znDSdirT3iUNfq6qDhNP/viurL5XKX7sXG+6eg7ZW/YuHp+CR9U1QXioShB113/qDaSHLqsyJWxFgVN53vi8QioRFuACNDIjkVmTjIvhslMGApMxEKLtgP/ejiMvlFXgRaV3j+U5qtbdqUA2hEMUEncoB/wKDZznyC5BLUV1V+twf0LriRt1lAwdVtCjOHZJOJidaphCzxUshgpxmxQVYCBlbv3ov8pnMAzI53i7xneHSaT/kdLRBKILSZJf//P/1+k8xY/MyTPhIPWyG8hyY07BNdU5yhmmM3XyiOui5wOovt6JqzeJUlzvB7X/P2xTDCcR6wMd4Y5ATI95unRbZ/8Ur2fswNn38umqALQCY1LYmqJtwYNajqOYNFO+6T7e6Yetb/8AkxYXfmxVyKoKcBHcLgk+e/o/coqgTVu5HmclpbqxTjZtjN6cENKR2wumwI+eJiUFl1KoeShPqk5XkbA9y4MKaf8xVvZaA8D+mqsoP/OU+4W9kqRXQ6F38bDqZnFA9abzdoDd88By23nk6qg4Gt0FSfhaaszorLqiSy3+ysUqe9jRulyuo2s2b9VC2xWip/kbVkFZ5t+jUCWKKtt6OKS1fYuNbD/raiGlSdNcOVfWlvAu3CTvExpd9j+1tLRCKC6Hy9zC1WXvCTr2qHDPcmoPcSe1tSVxOR1B1mOb2FYGWSREgQfF8uAaoWpTVAYf37gg5qWs0Y8soOU/4q4iFswUOe5vvs5EiyOR4L3MuyZ/JKdn7cMhMSuVz6pGCbYosRMwyOSF+b97zhBbloIWtJ6ox7sNLMfFT7ekLvBf5ttbm9u+Y+vOZXnlLFCXWptd+yOl0qjKjqXIDNnz4PLZ8+Q7qD2zxPb/hnvM01zcHnA/dYdqv2RuCA+tQQY7VpQ5ylD3RHC3+zzsFzdizpRxH9ve8oSq0MMiJEe8XLrBn0sRPFwKu0BE34B3uO/iE2NqifVcgAk4s3uoqZW+LBHcrREC7H1l5MVVmnRQ/GIvkOdnIbjeO/+NUOB8s9JfTkqa6iJhkJ6p1enAEZjvKX14elOo1O71tctyYXr9S9Zq3HKEoG0AOaN7m+1/54/Utq3PnkygpJ89ULBPwHitPEN5jm1L6a4xzbMbhl38TtF2HPUxVj6KRpylgJFaHow2b/34esh8di8wa/4i39d966smVjRvlEwfUgWeb/4Rkb2uBkGUc2rMdQpZR+b+XsP8v/oHEcr9+Aan3DUHZS3doFlFSVN8oe1iEkoM6VfDS1HBC9d67I2j30dKsznJ6pYlm5G4KvtuWZCf271gP+18LYP4o9DhDDnubKpNjcttx4tgRrPvvUxCOjs/3Vn+iRvUdyX+uCBNP/C/q7YRrMJ54yD+Xk6nhEJqXj8CG+y4AAFWj5HDcAW1yQo1/Ulz9su9z2Ld9rW86GQAwRdAbMxKhMjnmgCDH3tbi+z62KYKclu0fIBQJAieOHYF811DPWEgdaJOjxzs+k3BoBzkuRxtMiuPoixOY8tW1GL/qMsh2//duSvMXqvJ6WYQTyvYwrjATfDo0Bhs0BwSyylqGRLe63CZFtbkyO5WOFgx7/Ry4n40+09kdOE5OjNTXVmPju49itBx8dyYiaNfgtLdpNudqaahDcmpG0POm5GzVY3f7R6ls2GaTWwFFkFN1cDda9m/wPU521vn372hT1dDXHj2EvWtXYpqsziS4ElJhVgRtJtmB2oM7MFDrmBx2OOxt2L3+Y4yY+j3V4F5elvYgxxJB1kbJ7XJh7WNXYtTxj33PKbtxamZynOHT6u4QQY5J0eYosKdWkqMGLU31qLrvDNRkjMOMG16EK0yQo7zrNgWk/O1trZjc6rmYjXZt9z3vOOzpcq/8nE2OBlXgmVLnv8Ny2ptR/q8/onjfIygdfDVK9j+u2s8Q2ZMVKN55t2YZlQ0zmxvrkJgcXA0IhG5P0dpUp8reuA5uQNlTizH+p3+C9taAlsY6pKZneZZ3+VuP2CQnBgV8JwFPsH3iraUYLLWp3i8tTfXHVUHOtKZPgEdGQ3v87ch989QVGBjwPtikyIIO5XerrbUJIVqgYVjrZt//hTVvwSwJZDV9CkA7k+Owt8FqSwx6XpnJAYCxzi1ByyitfftRJG7/j2qaCQAwdTKTU197DNtf+ROKdYZQAACz2x/UO+xtqLtrPFpNKRj8x41wNvtv1vrXlIbemRDYueppFEt2TGn5CqUIzkB3VGtTPay2RAiN9neA55yhzNiqitWof+xeFuFSDWEQrieiHNCQGAjO5CiDnOHuvWhrbYbNlgTJZFJVS8mtwcG/Qwr+TvVEDHJipOZfC1CkuLtRknQieyW9Nh6tzXUABmu8EpB2bA9mXG2K7osBQY7jmR+hRHGBSHX77/gDq5akR4sxDeqGaADgTkhV3YmbZCdaqtRpS4cwwyq54XK0ovL/foEZte+gfN2FCG56Cdja66WTRFvEzRLGNVdg3VsPBzW0U5VT4/2MZPZvVXsjxYW5rqZKNQmq2xl4gpGw5YN/Yoa8D8NO7PNsK1yQI6uzCUp6A/olH9+KbWUr4VKMx2R2Nqs+E+VFyNHa7GssGxjgRERxAfP0xNAKZ0MPMmZvrlcFOd7eHuX/OqH5nQCA1oZaYMBQAJ4qqASd5Xz7l51IcIfuouzV3FAblznkpjZ/jmPI6tC6yixGS1NDyCBHOZSAWTHSsux2a7bJaW1uVAU52WhA2Ut3om+UvWRUDdIVBjaHDo7C+fq5X6G4PvTcX1ZFe5H929dgJI4D8nE0NzfApQhy0sOMki5BQLQqqmdjmMlpbW5ARp9c3fO92+nUzXqZmo5oPq9q6wanqtH5jnfvR8mCvwWv5F1XY7DBUEEOACT+LR8VmXMw48aXVIG3MtPk5QjVGaQHYZATI+N0AhwAsDXqD4Dl5bS3aCaL25q0f7SB2SFvN0llb4tEtKmCnMA74GxxwvcrCmzElqUR4ACAMCWoLlgm2QlTtfok1yYlwopmuBx2zKj1dI3WbJMCIMnt+fF4J1SMhFVyYcbmZSGXERqNIcONtQGo2+142xoIWQYeVt/nB2ZyBCS4a/f5HjsddrQcCV1nrQxyzHJgkKMdIE1qWwOsVLddMrtaVG1MlE55u5MpZcVJMHDGa6VQw8Xbm+qD2qUBQHbdZo2lPTzBfXsRnA7oDxPnYZKdMEdYbdIapyAH6Piw+cq7ZuUkjtForKtRfae82loakJHdV/Vc8U79i2O0+iH8eC96ag7vx/QwAQ4ApLn8VS/NNf5u281/n4KhiuUSw94sCZja6nyPJMVZVzVafAfsf+uvyPzFo7rZGpezLehmxiuxLYJMDlyqLv4l+x/Hwd2XoWDEBDgd9qAbAXNbcCYn8GZE2UnBa0bde56RjhXVVVrZKaepd2Ry2CYnQh0ZWM2rb2voSQcBwGVv0xyzwd5cFzSvU0PdcaBJ3XLeO5KlMshJEm0QijYVgZTjVrgcdrQI/cG4fPuRnaqsQaqzFhNPrFIt09Y+SH8kvVxS5Oi70UYi8A4FUA/Epef4Rw/5/pdkBw7u3oy17zyOTATO9mxXjShqgoyRh970PV73+j0o2r4coSirFoKDnMinZpjS8iWyV/82/IIdoDxhKxsfAuq2MqEu7s6W+qgnpnUqxu+IpCGxSXbCEmYQSy97U21cJso9joyQ1XahKIdfCBVMhrL9w6dhsdcFPd/R7XWFhqciC8IHyYew6/Zp2FX5OdqO+hv590OtKshKkkJ/ribIMGu8RwBQ/nzoG6dwio6/iV33/0DV7kbJ7bTrBuJpDu1G6MrflVU4g8ZBOnHQcyPV0hQcGFsV3fy9AudYEzpV+LvK3lYF3iUH/i9oGZc53K1Hz8AgJ0J6DYAj0V8O30vDU10VHORkrP49pDvzfSOo2ttakH7/MF+Xbi9vF2xlBiNRcvrGLgnH5bBrDg4WyOxsguuE/05qqLxP1XAXABztI5dGMt9MmohPkOPNHLS1Nvt6PgWOKaJlRt17vv8ltwMFz5+O6RuWBi3ntLdhe6l/yPbRzm2qifyKv74naJ1AkuIkYgm4wzu+L7oqgHwR3F00FkyKIMcZ8BtQNkQOVV3lam3QbHwfavqQCR8v8N1YRBTkCKfqzjMUR1NdXDI5yaK1w5kcb3WV2+VCzbZPOrSN4p1/87QvCuDQaE/RUwxTjmETxkj3bvRfcTGk2j0d3p9FdiLB4Q+glXMkF+95sMPb9ZpgX+9rZxjI7XIG3cx49dFoywmoh9xICJi3DAAcjZ71WpuDM/5JLu1aANU0FzqdYlwH1gUN9xHIbekd1VVdEuQ88sgjGDJkCBITE1FUVISKioqQy7/22msYPXo0EhMTMWHCBLz33nshl+8KgeNERMMcwQzFLo3eQIBnMKkEyY3j/70NAFBzWJ0Vqkwq9uwDbuyoWIXc3a91qIwuZxvMEUw+WNjwPxTvvj/0ttobNAY29G0SwZF/YIAUK947lK2P/Ax5T0/Dxo9eDTmgmBZziDYetWUvYPzqy3Vfj4Syfl456jIATPnq2k5tO1aUvb6cARfLFkVVaqhZuN1tDZrdjK0idKZvzWt3Y8uX72DvK78LW06z7NLN5Gz+/rOqx66mY+oximIkSXKohiOIhrfhfcU/F4fNAEZr5Js/wLr3nonpNrtLqtSKhNaOdb0HAItwIFExPk24SYy1lGeHzj5ltgWPggx4qrjNOr3fvBOTBlJeO8ySCApyXE2eajx7c3AmJ8WtHeTkrVwEwNMb0BvkbEycrl63bmfY8XDcCQxyAACvvPIKFi9ejGXLlmH9+vWYNGkSZs2ahaNHtesgv/rqK1x66aVYuHAhNmzYgAsuuAAXXHABtmzpXOO2zrKHGzQtAvtNBbqvuR32kPeAYxrL4LC3BbXRcSV4+qf0Qy1Gv/eTkBPgheJy2HUj9zUZ52BHwtjIt9Ue5AQ29O3SwcDbq9S8d7aTPlukWf8cSrI9uAum15Cjkc2lFYpystbAIKe7eavilG0I3K11qmUCA3+X0D6diLZG1WB9XrYwx1y04y6MX3VZ0NACWmxyK9KEdsYiKaOfujwNVdoTpsZANG3LlLy/vZLDz8WyOD7TKm6My3a7g80ZunFxKBbhhE0xwWZHgt3JV/1fyKr9XLd25l52OmCOMNuoR2pUN1CWaveg8n8vqcYK8sqQtdt2pYpmVKx4EBkPDMekw68AAOxJ6t9If/uesD1eRS/J5MS94fF9992HRYsWYcGCBQCAxx9/HP/973/xz3/+E0uWLAla/oEHHsDs2bNx8803AwBuv/12rFq1Cg8//DAef7wDvUNixNHSiJZOtsQ/YU5BX6G9jWZ7AxIloEWv6ZvkhOuuPPQHVOVoSUjqdLm8+3dIsma7oJZ+49CaMA2DtofumuvVZEpAiyyh1a5+z8xSm/7xxZjd1YwWZ4uq94SjrTaq92qQa7vu8o1SAtJ1PstIjWotxTe7NqCtqQ7JwhGTzzFWmuqrkZqeBafc6ivX+C1/xhcHSzH5mn9Cdrtw/PgBZCrLLAk4ND5fe3MVTO62oOOThT1mx5wsjgHQ3p4DbtXzpuMb0ZoxIuJ9twormqQU9IX+oIltworEMO1BQjGJNnxx/08xtQd9B3qqVOe3Hf7euOCEXbL51re7W6PflhlYM+o6TNeZzw2SQ/M812xvQmonv/MTa15XrT/h+ArgyxXYbh0ftF2Tzvl2V8JwjN90q2f59rK2pOSgpc6/bDLq4RLmkGVts9oghIDUw7+zkhBhptXtBIfDgeTkZLz++uu44IILfM/Pnz8fdXV1eOut4C7AgwYNwuLFi3HjjTf6nlu2bBnefPNNbNwY3IPJbrfDbldM0NbQgIKCAtTX1yM9PT1o+Y460ViDM974Xsy2R0RE1JuV/6wcyTGstmpoaEBGRkZMr99xra6qqamB2+1Gbm6u6vnc3FxUVWmn9KqqqqJafvny5cjIyPD9FRToVwl1hi2xd6TmiIiIyKPXj5OzdOlSLF682PfYm8mJtSRLEp4ZdhvGfqQ9J0ok1mafh8La/2q+tn7ibcjf/CjyQoz6qbnNUTejcGf4njzhbJzxd0yquEnztfUTb4M5MQWTKm6OaFubkmZgYmsFapCp6nHUEWuGXIPp+x6Ler21WXNQeM1TcNwxGNY4NW4GgLVjlsCcmIopG/7oeZxzAQpr3uzw9o4hS7dapB4pyEDotmGHpdyY9LT62jIKp7g6NjfN2uwfYPD5f0BWTn+47x4Z8ai/0VqTOxfTF/4Du+8+AyNcwXOHeR2a+wEGvDKrw/s5hizYrv4Y6Y9P1nx9w9Q7kLz5eYxy6lfnHl9Ygb1v/hWFx9/2PecUFjT/sgKZT0ztcNnC2W6dgDGO4PGIOvP5hnPoklUYMGwcGuqOI/3RCZ3e3hGpH/pHeV4MRfk7Wp9+FqY2rNZcrmLQQsw48LTv8dErvkS/fM+oPBve/6fvN98RVVJf5ImON6CORiSf9bqxSzF828PIRCNcwgyLFH7IlHUTbkWSped3I49rkJOTkwOz2YzqavVJt7q6Gnl5eZrr5OXlRbW8zWaDzRZ+fJfOkiQJyQkpSI6gdk/vYpRgzdRd3+qWkSy7kRxl89zk5D4RlSmcBKdTdzuJ1hRYElIj3o/VZEOyEBgUog1DJNannon+E2Yjee+jYZdtQLKqh0KS241Ekw3JcMS8xfMu8wiMdHsuqslJWUjKHuh7b1KHnYnNskDR8Tc7tO3DBRdi8MGntF8z56K/+xvf47VpZ6GwUX2ClkxJSJYjP+BjyIIJMvpA3Zgzz3k84u9iq7CqxicZfeHt6Nc+WvGmxEm6M8h3ltVkQ3JCMtzWXCQ7PfOnNYkkVFv6Y7jb3804yRLZ71ZPCmQkJev/dk/74bXYtPWNkPuw5Q3DIXOSahm7AJL7DEBC/FoMQErIQrI9ePvOlKFIrtuhsUbnpSVnITkhGVKyG0kxODanpQ+SnbEbIiFZMeZVstuh+7mVXHo7mu56zffbSE/K9FXNJEV4LdAlJcfkvB1ov2kgctw1SJH8PRft6aORfDz0Z22VBZJ+VYFvD+5E48f3Y1rjxyGXB4CUpKwe3x4HiHN1ldVqxbRp07B6tf9ELMsyVq9ejZKSEs11SkpKVMsDwKpVq3SX70omc2QxYbOUovm8ZAueg8pLuOwdGkjMkpIZ9TpaEra97vu/fKx6+HazxQqTxRrxtmRT6GU3fz+ysXum/vZtJGjMuaOlBer33CTbsWdLmHlsOmB9yhmo6Vfse2xJTEN6P/9UBwkpmZBt+nXJW2yTQ25/8iW36b5Wn+TPUO6/5GMU3hQ8irRZ6N+BaXXhT76pEtKvgt+nbBH5KLYnTOqpDJS/k5ZBZ/r+32/SnhKiw9pnSHda/b+rNsmGjEVvBSzmL09Z7qXYaxoS3W4gw2oLfcfqNof+npotFoiA34UMCQlWGxo1PhctkQzWGchp055mwp05DBtKHsSaycETs1Zk/SDq/Sh53ytLQuTnjFBardnhF+qgqU2f6b5mtSaqxn+yWP2fscnSuRtre5RTIuxIGIsNyaeGXS77hs+xefQNvscnkAY5JTfEGh5yWwOy+vbHKVO/C2dATys95kS9med6lrh3IV+8eDGefPJJPPfcc9i+fTuuueYaNDc3+3pbXX755Vi61D/Y2g033ICVK1fi73//O3bs2IHbbrsNa9euxXXXXRfvooZljvBC75RsKB1wBdZknoujiyp9z0tJoYKctrCDL2lJTOsT9TpaJinutgsvXIyyvHm+x5LZClMUJ6xwQc6EM86P/EIjRfYVbTWpTxoJziaMWHFeZPuIUPmYpZh68zuQUnJ8z1mSUpGVO8j3WDKZgcRM3W2M/u0qbD3nJc3XZCGFbPvlyPAPYG9LTgMA2IV6MPfAsS22J/hnHK83BQdfKWmZSEoJft4aQbraq8Gi/g4mKL4rWaec5vv/8MA5YYO8qJg8wYtsy/Q9ZZdsyMkbhN3m4f7FzP5Rv4UpAQ6T/wK1PtUfhG3XGSYhGw2wWELPnhUuyAEAyazeRoPk+QwbNT4Xt0bPPbuk/btqE/plk5N0AgSLFVNmzcfQ4vODXkoYc67u9vTsOO8/vv9tSZ4bjnDvWaScCdo3DetTz1B9v0MpHbAg6v1KJpPqnGxL9AejpoTOBTlOs/aNsB6XyQpXQlrY5dIysmGy+svZYMpAyjC9GeL8Rs66xv8gOUd/QYUEBjkec+fOxb333otbb70VkydPRmVlJVauXOlrXHzgwAEcOeLv+3/qqafixRdfxBNPPIFJkybh9ddfx5tvvonx48fHu6hhRZrJcUpWlCx6ANNvfBn9BgzFmsl3oGLS7TAnZ+quI1z649SEkpajfXfcgOh+RF6ykDx3nYoTsslihSUh8nlKhDl8QOQOMd0EAKyd2j5jeYSDddkDThrjWtdGtF4k71N5zoUoO+W3mPrj3wAAzKn+eYCsyem+2bIBICW7P0yJ/pNyeZ8LUINM32NLglU1yZ5SCxJVF+RA5uwhvv+9gUmrpD7ZmhVjW3xjHoaGzDG+x81m7SA7XJYinBar+qRoVgQ5g8fOULwiwRnLSf3aMzkiKdP3lEMKPhbJpDjNmcxwKYIcZ4E/CHOak1Carz3Ao2ob8GdV6trnUZcjaJsgTP7zRz1S0HCBZ0ycZnPwRXxTSnDm2qkzTWmtSTtbAwBSsvZNkNSeidAKRJKz81HW76e621Sq/sV6HF1UqTo3egP1wPdMy7eSdjMEJaHTe2fqb99BXb8Zmq8FKrry71Fn8AB1ZtSqzOSEuenblFgY8nVXlGPMuE02yAmhg4rynIvay+b/Lraa0jDxuxdh7bS7sfdi/xxhypvYNZPvRE6eoh1rQABXMemvmvuzJocPunqCLhnx+LrrrsP+/ftht9tRXl6OoiJ/ZPnJJ5/g2WefVS1/8cUXY+fOnbDb7diyZQvmzJnTFcUMyxThnYkr4I5r+gXXYcaPfw0pRJAkuRyqH1TZiBtxUMoPu6/sXO0g54ilY42vXd6vhEkR5CRYYQ5z5+IQirvliIKc0AFj4Y88dxZ9BozQfH3vT/+n3n9AkBPJKNOA/246UNmo3/u3NbgYxT/7ExKsnvfAmu5P59qSPOtv/v6zqJhwG4aOnQ5zsj+YkJOysTt3tmrbrlbt0bNbNC7QSsm5w3z/J6Z49tsWMHWlRbhQOvhquIUE+9nLIVv9J8bWhEzN7ZotFsgdHPNHFhKciepsgbKaIjHZv39r3hi4A+a70QsqItIeKJuS/fv3ZmmU0yuYFcEFTBZVkCMpsrNucxJKrnoIlaepG7prVRPsSCvG1rNfhPuacgChg5wqtAfFijmNkpbuwcjJ3wEAtFqCg0+tIfO9g2wGajDrZ3MtqTp35e2/Ua1zmsWaiOJfPel7HOo8lDtwOPoNGIoERaAcTTVVkzn8rO1ygv6NiGQLfaEtG3Itjl+zFSazGW1RZE/WTL4TgHpaBWXQZglRXSULCY6xPwm5fZclfFmUoxC7TTbdavAdCWOx+8fvYcoiT9vFBEV2396e/Sn84S8xdJz/uptV6C+fyRpwA6s498tCQu7Y72ju15rETI7hmCMNcszaPwAp1MXf1Qazsk2OyRI2EACApBTtH3lD6lDN58Nxt89mDkVAZrHYwgY59ZLiB2jSfp82JU7H/ks/BQDIYTI5XumZfXBw3mfYE3AXNuiUKarHrg628rebgi8mNciEJcV/4bQkqy9CSZn+Om5be0Zlwhk/xoyLPJmehBTFidtshSlPnVJPTNe+8ARWuQXKGzYJpfnzUTr4at/dsj1gJmALXChZ8Dc4f/8txhbPBhRBjsOaqbttd4hTQatQf2/Lci/1vwYbZKv65JsQ8F355sL3UT56CabMujwoGLD0G62737DaqzItivfb6Qui/EGOpMyOmcyqqiVlFZI3AFO2P1sz+U4M+0VwGzKT245xp52HPu03GXrZhtKCRZCv8PSoNDn8IzJbFW3NHAkaQY7Ghd2lcz4I1WYlIVX7NW91i8USvE1v25O10+5GeZ8LgHmvolVYg6pGlYaMmY7ynItQOjS6ZgWt1vBBjiVneNBz3nZ9UmLosVRs+WN9n1Gk5xwAGPP9nwGA+pysYA4MDNp9c+H72HPhf9FvdOg2pMqbDz1tw/03R7LZqnusLpMVIyad5vtOpWT7g1JnwHer6sq12H7uqxhV+H3fc7Y09flIGfi7YEaCzrHamMkxnkiDHLvOHXOo6q7xR95QDQlfUHxhREGOHlf6IM3nNyYVoRr6d37eIEdSZXJCBzluIfmDIwBC5y6ndfhsDB41GQAgR3FsBSMnoT5JnbEyB5ycAzMEek5AfaLIcvunbtiQ7Km62D18vqpRnTUgyElO979/iRo/dJuiMbhksWHaD3+FslNuxjcXvg8AGDV9JsqG3xC0njfgOmAaoFn2pLQMlFz1IEoW/E2xTkDQ0F5d5c2gmBL95XMn6l8MtfJee02DUZZ7KarmqueOM/f3dwtulRIBm/+C7K3uVBo+8VQUXbIUJrMZctYw1WvmpE4M+NWe+bQqshWu9qDv+Nj5AIBNidNgDvjdyXpBTnugoqyKGHHahcjI9ldPelnkgHm3ErS/fyUL70X+kFEAALNDZ+JGRZsiL6FRNeHWqa5yJAWXz8tsTcSajODu81L771nrnGZpb9NR+MNfouj651AwYgLartuEo5dpd7UGPFmOouv+iZL5wQ2ZQ3GGCLy9Rnznp0Ftaiac4WlLZE4MfaG1KW4o+jgOR1wubzVegk7bNL3zYVbeYIyYdJrvPdTiFGYIS/jq/+R+/t+KbLaFCHLU28rs6z9Xuq3q9ydv0EiMKfJ8H0qHXoc1GbMw9lR1Q3NlkOOERbfzR2KKfhvTnoRBThQibZMT+MXyr68fJKVK/nmVdl3wLgYMGwfRiSkQEgdO1Hw+40d3ot+tu3Ec2l9Qt7ehr6Ks5gSbbjQPeH4IqhnUdU74JkW7nmiCHACwp4aufoukTQQAHEw8RfU4G/75XcZc/xp2nPcfTL/0VlgS/RduW6r6bjNbUX+dnJYZtI+kNEUwYUmE2WJB8c/+iOETPdUeksmE4p//RdVWBwCc7QGL+bL/qJ7fap2AtdPvRYrGvk5kqBvLHrSq73qV9fNStjrAUAv+rh1PGYHiax7H0LHqyfskRRDQJiXClOR/f1xhTimTL16CXZaRvsfDC8/BhpTTsT71jJDraZa4PTJLTPe/3+7278H0H9+Aby58H6fc8I6nMbh3HckM2aIMcvzH4puLR9Et1mLVvpgluNVBjqTI5Gg1GgaABJf23FqyRrsZYdXI5OhkSOUQDUVNFium/+ZVlPZXVwt6O1EEZt0AwGINzjhn9e2PgpGTdPfTUXKIHqdetqRklCy6H9vPfRVOYUbZEP/ktUFVLe2OIhvlORdi5FT/KPWpIvL5B8NVueld+L3VdtZw58sIqvRT+/rPM8JsgyVF++ZUDqg5yOzb3/8gRJvGkvl3YPpvXg1qB6i8Trkk/UxOsk4tQk/DICcKlghb1OvVIUfapicrbwgAQCh6FtVcHTygl1fgDLIAkJCcjkOXlwU9n5SWBclk0m3E6MvkKL7oFksCzAnqelrA36tja9ppkJVzAykagiqpghyTfpCzb27wHeP4ecuxJuMcbEosROXpwXOYiQiDnJZ09YXe2122InMOEpNSMHr6TJgtFlXPgaTUTNU6yakZ2Hvxh9j70/+pqh18yysuulKIuvvgINZzQhowbAy2Wf3ZknG3fIHC8xZpbmPMz+9DefaPUD72jyjvcz5yLldP8Kjc/7hzr8La9JkoHbAAa9PPxo4fBHdBV3Ila3clVfYytJuSYM3yZ55cYYbeSkxKgfUnT/gep2XmYMrN/0XuhXeFXE+LaH+/UjL95fROKCqZTBg+8VQkJqWoe1dJ6kxOQlIaDkue9bOmBze2TdALcgIyOZLVH+RUm7QzK64JlwAAdlrUVXTmjOA2L5JGkOPWaZNjzhigW5Xk/awCe3Z5q6sCL3BlIxcjd2Bw9VDc6PX+UvA2jB9TNAvu3x9A8RV3+l4z6QQLtuvLUHTdM6rPb2dR5LO7B2b/Ag0YNh5rMs5Baf/LUHbKbxVl9Xy39IJjAHBICaqbSD0JimyQMNswbPpszeUCe/YpAzTJHf18aurqKv1Mjt5vo6fp9SMed6VIMzlCp7418ESjx5sqVV4EM7JzUT5mKYq2B/9QJ/7uQ+Av6myDJSERqRnBJ5CU9guwXpbI3yZHnclRavz1TjQ31iGn/2CsW/0CBk0+C84nz/Evn6Jdz25WXAj0MjlNIglDxgT3TEhNz8L037ymuQ4ACJ3sUZD0AYBi8NSxCx7G+q/OxsQz1A0FlXXuWtkaZSO+QCmK3lYIMW5N4GdgVvS6ijSLl57ZB0W//rfu68ogJyk5DYWL/6O5nOb+0rR7vii36TAlIUXRw88VQbuHQadMRkXWD+BO6YeS9ousJcSdr672wdT6D/JnhgLvagHArLqQS6qAOCVnINJuLMe+w3swSuN7p7wjVw4CWZesrg42Kb7bJxJyke8IHqF36uwF2JV/CgpGqLOsSTmDg5bValCrF+SYktLQct1m2B4Jbt/k7ekmTAF36xo3BZVJxSiet0xzH17l425F0da/APD00CkOuXQErMmomHAbZmy+TXcRvYbsgLr91IbkUzGl5SsA6h5+XtPmLEB9xR/CjhoOhO8ZZjKbfeejspf8QZc3M6YMDI4iG/LCVch7ehoAT+AQsn1mO4tiG8KSiKy+/VHe9ycoOva6ajkR4jdnkqMPcpRjALlg6XTvy+7GTE4UlJkchwjRU8qmHeRE2qbH5AtylK35E3zjggCeLqzrpv/dsz+NH6TZmqgZgaeketLDWrONe/bpeV4ZzVusNvTLH4o1GbNRnnMhMvrkIn/IKFhtiZg2ZyH65g/Bcav/bt6arB3kKE9Iss64Ispqu6hEGOQkZBdgq9WTdt9nKkBqehamzr4i6OQpZH+aVxW0RCBZMe6McLbpLidDfXIyC//0ByLC8YHCUWYPA9vKhGPJ1O5Vo0xnO81JyOjnT6vLEZxSJJMJM254ASW/+IfvuVDVobragxzJZMK+uauxLvW7yD73D0GLmZQXeMmkalSf0XcA0jKyVYG1pDgGZaaj4LefYUPJg6jInINBlz2iPibF+9yS1B9aJJMJIyd/B8mp6iqa9LzgakStgdbcOtVVJksiklK122v4zjkB3ydzB+/Ciy6+CW2/O4SmxftQfHX4kchrEbrNlcma7GuwryVcD9OkLH8nAHu+/8ZDL8tgR+yzD8pRf73fF2VgIEEgNcNf1STDFLa6anvCWHXNQXvgMeOaJ4MX1jhXlPe5AC5hQs65S4OXD0N5nnZLlpiNd9RdmMmJgvIi0SIlwto+PHjN1ZuRlpkD212ek5ukk8mJtLrK1B60KO+uJZMJkP1ZAfPSfZgWYuA4c4ItKAJfk3EOpoe5Q7HCE/krL2QWqw2SyYTpv3lFd71+P38K61+6AYmnXwub4sdZlnspiqs9g98pe7m4rNonv7XpMxF6hIlgspBUbSJCSek7GH0XvojS9x7CsLOv0l0uv/1u2yHMsEZ5QVAGncIVIsiRJFWLX4siyLFbswC7xkpRSoiwcaDW/FIJydqfkbJhrsucjGzFiM+pokVrlbCsHZkAV9HeYMiYQgwZ85bmYsoMrAQATn8Zs3KCA5I+BacEPQd4qtqmzJoPzJof/KLb/9u0jDsf+OrD4GV09B0Q3BPSotEg260zyKbJkqDZtgZQZMgCMjmRDmyqJfCGIBTz9Wux68BO5L51CdI1MigmjQa6ZbmXom9NOfpc8z76a2SjlUZO/g5K114Jc2YB4PBvX+/9cEoJMZ/mRYsyMJAgVOdih2RV3UTaRYLq93cEfTHo1+/D5fJndiXJ2yEk+PytdUM049pn0NxUjyFR3qAB6uuUG+aIxjvqyRjkREH5xW1DItAe5JjNCaqRavVa/Os1PC7tfzlKjni6RB4wDUCB904vINsiFEFOqIZtgOcOTpnmrZj0V8z48fWKJfzbLh30S5Qc+D8AgE20pzcVPxy9E4ZS7sDhyL35Xc8xfF3pfyHF3z5BUmxTr8HhqIUadyphyJBgUvTw2WKbjLFtG1Ex6rdIOvgpnGMuROH6JQCA9JyB6JM7UNVDSUtqehZOXLsDCbZEdGpwepd+pBJYRaQMcgou+Qd2PPszNE28IuqgT2lM0bnY8OWpsKcP7UDVgvbJTTlGiNuSpLprtkjRT00CqO98S/tfDiQkwXZ8G6Y2f667jhThQJGq9hWSpOrKrZXdyhs0ElvOfh5J6X0RaesU5QCPU865DOtlF/oOn4JIRqsKzOwAnpG0g/ah047NbLHqZul8QU5AlYZm9WAc5iHK6JOLjD65aNCOP1Xt9LyKrwlucxeKNyOorDbSG1TTFY8gR+N9UwYGEoRqFHCnZFNVV1X2/SFso85GVsFoHN1ZhjHfuxQpaZloa/H3xgs5jJXO/lM7EOAA6uqqzvTw7Sl6/xF0IWXQUGMbiDy7p/uxN/OyKXE6BrdtwylnXKy5vm51gSKqH3DLJt8PJKidhKJ9R9joOmDyt8ALgvLVkivvBm7zBDm+iRYV64dqRKclJcPf28Ok7BGg/OFrNE5emz4ThWHu3LTIkFRtIrLmPoqjFiuKB40E8EcIWcbOTc8CEBipaL8RTlZf7WqHSOw1DcZQeT/yivVHjhUBQcS3/Wf6Lor9BgxFvz90fu4ts8WCKb97v2Mr61z0lEPay+09ktxCingARi3Ki4BkS0PxFXei9MkbgBBBjojwamVS/lYkCRandi8npfGn/TCibXuZA6ZsmTr7iqjWX190P9LWPuxr82PVyOToTZcihcgQJ9i0Rx/uUBuoTtje52zNSWvT8yP/PYYjmcK3B3PH45IXph2aBKF6/50mmyqTI0wJmHy2Z1yewaP9M9KrqnBD7iO2wamyPZPeAJS9CYOcKCjvCJuyxgFVlQAAt9tzFzf+5g/gdNp15x8KnNStInMOxIBpkJr9kyEqA6GgNKSs34g1kBwY1AQEPeEbtiqCnCgn2kvL9Ac5ylGeJcUP1aRot1OWeylS6nZg6LwHotqPl4AJZkUmx5achpw85XxSJoxc+hUkSeqy1Gv/m0tRVXMEQwu0R2wG1J/Bmsl3YsqsK7qgZJGTdL4jyoboor0n4T7LUNXM31HvS1nF5w3mddqgKBaMetuABHnMj4A1n+GAaQC0R5OK3qSzLsXarW/CnV+I8DMFBZt67gJstKUAn3l60WXnB7fT0QtyQo2+6xuJOCiTE7xOZ4asCGfilQ9j7eoSmBNTMeUrTxfwslG/Q/Gk02O3k0iCHFMCOjAPckhjZy3E4e1P4GBWseqzPyzlIl9U49vEU6C8dXOZbOoJj3UzdAHVrHpi1H7Pv191m5zervcfQRdSniwTR56Btc1VkIQbU9vr9U1mM2wh5uYxmfxf1UOXl2HGMM+8QjvXfgTseyRo+cCTTuYppwG7/xG0XKC9psHBY1qESe1/K+VhoKjSfC2S6iolrW7VAJAzaJTvf+UotblnLgwaiyUaAursgkWjvUGoOaHiITEpBXkhAhwAOJY8HAXNngHKpl9wbchl463slJsx5OtnkAf/4IjKTM4e0xAMk/ehVVhV1bbe8VxqMidi+PGOBzkq7cF82B4oEVZXqUgSpp27EFsz8zFwdGcqAtXMFotuz7VIZfT3BzZ9+gUPCKmcT84hzNiSehrS2g5jxNTv6m7T1v5blAKqhcKNYB5rSSlpKPzR1dhe/oHvuRk/XeL7f33KGZjQ9CW2nPoPTNHaQAQiyeSEykx8Yx6K4e69Ue83LSMbqX/aifyAGyjnJa9izY6vMOrMueoymGyqHop61ZAqoaoSYx3kKL4bTp1BVo8iG5HNVd79GOREaW3aWUhpq8LY0y+A9axLolrX5fA3Qu3T338POarw+9hqfxHZA0dAWUESmMkZPeNsbG77F/oMGo3APge7LngXxyvfx5RL/ohBGnX0WSMCgwj1j+bbkT/HwK/vQS3SkQ115qczAUK/Madj36jVaG04jjGK8TesiuHmbToNXCMlw6QaL0Or+2hPNOjnj2HNyzcj7bRfoBOTG8RE8c/+COCPqLltMHJQB0Dda8R22ctY++YfkX3O72BVnAS947mM/tnd+PqxbagdMqfz3Yq9mZxwQzZEmMlRkUyQTCaMOy22M9THwpAxhVg79S4kZg/AeK2MoyKzVSdlYOrN70DIcsjspLet04Q5v8Th7U8iX3i6tocbB6YrKM8rE254HfW1RzElL5JWTNrSC8YD+sOJAQDqsyYAR7cBANamn43ChlUAgIrxy5Cw539AS/RBDqDdfGDwqMm+Ed6V3CabatyxSMbMUQYy5WNuQdF2f/ujWPXE9BdH0YU8YDTltekzIQ/+DoZozF7fU3X/N72XKbwp9ABqoaT18YcwtoCeT1onXa30sXc480AjJ3/HN+Gf0reXfYm6I99gfMBrgdsuuuQWrHkzDbnjz/SkVjtyAVGo/sV6NBw7hJEaP3JAPfVBUkrnghwBSdUjIKGXBDk5eQXIufHl7i6Giup7oQhyBgwbgwHtmYqqA7v8i7QHORl9cpHxxzWxKYS3WjZcJkej0Wp48auSiQXvxLQA0IBkpMPfE0woxgBqNnl+M5GM5wJ4Gjc7f10KPDC8/fmedepPsNrUM2F3wOgZZ2Nt1V1Iyx+FUTrLTPj53Sh90Yacop9i2sTTfOOLCdkdcrwZlzDF7GLpNiciQTnkRZSZnKK5v0dL09VIvrf9RjnGQY5FEYC5A8ZTEqYEzLjoxpjuL9561jfd4HLyBmHz9/8FW2oGTomgbUgsIvSBI8Zj4IjxYZeTTCZMvzB4PqWOyh04POTIqco6ab0xPiIlQ1JlbyIdj4iCqYNfnd5VivYcWuO5dL4Q3uoq/c/xa8spGHfhEt3XdcWhB1G8NF7+EbZ99CSKv30aAGDqOxJor1FuNQe/71tm/huN35Qh89uPMca5Lej1jKwcVGTOgQSB6bkDg17vigAwd2j4c1FnKINELSlpmSj55UPBL8iukN8NN8wxu1jKZhvSFFM2RNKWKLBNlbJHnpTdscmY9SgzOYFzAroyh8R0X12BQU4X08vEaIvfSUcEjNGisUTc9g0AA0ZMQIuwoUlKQd9OjqgpJEnVWK63D17VU+id85VttLTGOen0fr1tckKM5XJKrLJGPdiAYWMwYNh92PzZd9C0+ytMmnUl0D4ysFZbifGn/wg4/UfY+dcZutucceNL8SpuRLL7DcDBy75AYnIa9KcV7XpCdoW8qWyVbDEbRlDOHIo++YrAJMQwE+U5F2JQzecYOyc4eNv8vWfQvO1DTPux/mCKHaEchNA7kejWc15C48a3MWXun2K6r67AIKdH6767zqHF5wOVf8B+UwGCB53vvMSkFLTcvAvpZkunezwJSBg8dgaq3spBgyU7oiwZadOrrlJSZs305g7qiHVp38O0xo9RMMsznpMyk6M3pUm0pBin9rvChDN+DJzxYzgd/ouh2xKig0OIqUR6goIRE8Iv1NVkV9CQDgCwbsb9KKj4C2rPezJgOt3orS95GO5t72DyT29RDahoajmmu07Rdc/otruacOaFwJkXdrJUwZRd171VpONOnQOcOifm++oKDHJ6ML2pF7pCTl4B6m/4BvlxnGlWaxC0jmiQMpBhS0SfW7ahXw9ra9DbRBLkKAf/M3Vi5NxAU3/zBlpbmzGg/TunDHLyJs8GYhDk9KbqqkDKxsIui/YkwABgFi7d10ibcLs027ZMm7MAmLMgJj2Jps76OTDr50HPW1v1gxwggjHRYkzZJkeEG8ahF+h9tzUnEa07i9htO/zJPiMrp0fPNLvxzKewyzwCrp88C8Bz8e3qruLGo5hKROf7p6quimEjb8lkQpIiqFYGULHrDdR7gxzVbOohpjExo4OZnF4cAHZWQtZAmMdfAACoRp/QC8eYyxqbm71YUQ1CaICbxt5/BAbmHH0+sKEMVegL7fmgO64qqxCDj3+LVmFFb51jdtL3Lga+pz26NHWMqiWW3ojHioutJQ5tcny7V2RyIp33LfxGjXEhlxNin8mRDTDwW7Q2nvkUWnZ9hhlzFsFkMmFHZi76j5jcJfve/P1/wVX+BIb+NPQUM11N1TvVAJmck+9b3YsU/vBqbMkpQMFo/YaEHTVu/v0oXTEQBaddCq1+FkRSiIBgTea5SG45hNFTvxe3/SsHeIx2BnXdbVo7MBFoD6Q3CTAQfZBTNnIxBu/6N/r/5O7OFqvXCbxRGj3j7C7b94Qzzgei6ojSNVTzbkXSvb2H6/1HYGCSyRT1HDqRSk3PQsn8O+Kybeq9VL3uQgQ507tgfB/VAI+WBGxMnI5JbWuwJmM2oh0fu3TotUg9XIpJ5/4itoXsLrYQmZwoq6uK5y0DsKyTBSJDYnUVERmLok1ON1ftKAesM5sTMOyaV7HuyxUYf6b+pKd6SubfGX6hXsRs08/kWMCGxxQjkYzG3MMxyCEiH2WbHL0JOruKMm1usiQgLSMb0+Ys7MYS9Rz5k2fqvtbhhsdEAUINyNlbMMghIp9IupB3FWWQY4lRm5ze7vg1W9FUW43Bw8bpLmMR7t7ciYx6EGtW72+xyTMHESn0oCBHURZO1eHRJ3cg+mhOyeBnYSaHOmndjPvg3L8GM866tLuL0mkMcojIpydlcqDK5DDIiRTb5FBneaqFjVE1zMEAiUhTd7fJUQZZsRsM0PjqpM5NeEtkJAxyiMhHOZVIVw8nH0g56Wp3l6U3qb3gBXxtOQVbz36xu4tC1O14e0REPurpPro3kzN8wqnY+t4ktCTlRj0uzsls5OTvAJONP0s7USQY5BCRQk8aJ8eMcbd81q1lIKLejTlgIvKJZO4qIqLegkEOEWnq7kwOEVFnMcghIoWe0yaHiKizGOQQkY/oQW1yiIg6i0EOESkoBwPk6YGIejeexYjIRzVBJzM5RNTLxS3Iqa2txbx585Ceno7MzEwsXLgQTU1NIdd54okn8N3vfhfp6emQJAl1dXXxKh4RaVANBsgYh4h6ubgFOfPmzcPWrVuxatUqvPvuu/jss89w1VVXhVynpaUFs2fPxi233BKvYhFRSKyuIiLjiMtggNu3b8fKlSuxZs0aFBYWAgAeeughzJkzB/feey/y8/M117vxxhsBAJ988kk8ikVEYbDhMREZSVxu1UpLS5GZmekLcABg5syZMJlMKC8vj+m+7HY7GhoaVH9E1HndPkEnEVEnxSXIqaqqQr9+/VTPWSwWZGdno6qqKqb7Wr58OTIyMnx/BQUFMd0+0clENXcVMzlE1MtFFeQsWbIEkiSF/NuxY0e8yqpp6dKlqK+v9/0dPHiwS/dPZCgS2+QQkXFE1SbnpptuwhVXXBFymWHDhiEvLw9Hjx5VPe9yuVBbW4u8vLyoCxmKzWaDzWaL6TaJTlbqNjndWBAiohiIKsjp27cv+vbtG3a5kpIS1NXVYd26dZg2bRoA4KOPPoIsyygqKupYSYmoS7HhMRH1dnHJR48ZMwazZ8/GokWLUFFRgS+//BLXXXcdLrnkEl/PqkOHDmH06NGoqKjwrVdVVYXKykrs3r0bALB582ZUVlaitrY2HsUkolBYXUVEvVzczmIvvPACRo8ejbPOOgtz5szB6aefjieeeML3utPpxM6dO9HS0uJ77vHHH8eUKVOwaNEiAMAZZ5yBKVOm4O23345XMYlIQVVdxd5VRNTLSUIIEX6x3qOhoQEZGRmor69Henp6dxeHqFfZ+dcijHJ5Og8cuvwrDBg2rptLREQni3hcv5mPJiIfVRdynh6IqJfjWYyI/CSOeExExsEgh4h8VHXXDHKIqJdjkENEChwnh4iMg0EOEfmoBwPk6YGIejeexYjIT+LcVURkHAxyiMhH2SaHDY+JqLdjkENECqyuIiLj4FmMiDQxk0NEvR2DHCJS4LQORGQcDHKIyEcoszcmBjlE1LsxyCEiHQxyiKh3Y5BDRD7qcXIY5BBR78Ygh4gUGOQQkXEwyCEiTexCTkS9Hc9iRKSJmRwi6u0Y5BCRJgY5RNTbMcghIm2sriKiXo5nMSLSxkwOEfVyDHKISME/RSerq4iot2OQQ0SaGOQQUW/HIIeINDHIIaLejkEOEWlikENEvR2DHCLSxCCHiHo7BjlEpIkjHhNRb8ezGBFpYiaHiHo7BjlEpI1BDhH1cgxyiEgTMzlE1NsxyCEiTWyTQ0S9Hc9iRKSJmRwi6u0Y5BCRJgY5RNTbMcghIh9JNXcVTw9E1LvxLEZEmpjJIaLejkEOEWlikENEvR2DHCLSJJl4eiCi3o1nMSIiIjKkuAY5tbW1mDdvHtLT05GZmYmFCxeiqakp5PLXX389Ro0ahaSkJAwaNAi//vWvUV9fH89iEhERkQHFNciZN28etm7dilWrVuHdd9/FZ599hquuukp3+cOHD+Pw4cO49957sWXLFjz77LNYuXIlFi5cGM9iEhERkQFJQggRfrHobd++HWPHjsWaNWtQWFgIAFi5ciXmzJmDb7/9Fvn5+RFt57XXXsNll12G5uZmWCyWsMs3NDQgIyMD9fX1SE9P79QxEJ1stiw/E+PtlZ4HtzGDSkRdJx7X77hlckpLS5GZmekLcABg5syZMJlMKC8vj3g73oPVC3DsdjsaGhpUf0RERERxC3KqqqrQr18/1XMWiwXZ2dmoqqqKaBs1NTW4/fbbQ1ZxLV++HBkZGb6/goKCTpWbiIiIjCHqIGfJkiWQJCnk344dOzpdsIaGBpx33nkYO3YsbrvtNt3lli5divr6et/fwYMHO71vIiIi6v3CN3IJcNNNN+GKK64IucywYcOQl5eHo0ePqp53uVyora1FXl5eyPUbGxsxe/ZspKWlYcWKFUhISNBd1mazwWazRVx+IiIiOjlEHeT07dsXffv2DbtcSUkJ6urqsG7dOkybNg0A8NFHH0GWZRQVFemu19DQgFmzZsFms+Htt99GYmJitEUkIiIiil+bnDFjxmD27NlYtGgRKioq8OWXX+K6667DJZdc4utZdejQIYwePRoVFRUAPAHOOeecg+bmZjz99NNoaGhAVVUVqqqq4Ha741VUIiIiMqCoMznReOGFF3DdddfhrLPOgslkwkUXXYQHH3zQ97rT6cTOnTvR0tICAFi/fr2v59WIESNU29q7dy+GDBkSz+ISERGRgcQ1yMnOzsaLL76o+/qQIUOgHKbnu9/9LuI0bA8RERGdZDh3FRERERkSgxwiIiIyJAY5REREZEgMcoiIiMiQGOQQERGRITHIISIiIkNikENERESGxCCHiIiIDIlBDhERERkSgxwi8pE44jgRGQiDHCIiIjIkBjlERERkSAxyiIiIyJAY5BAREZEhMcghIiIiQ2KQQ0Q+QpK6uwhERDHDIIeIiIgMiUEOERERGRKDHCIiIjIkBjlERERkSAxyiIiIyJAY5BCRD+euIiIjYZBDREREhsQgh4iIiAyJQQ4REREZEoMcIiIiMiQGOURERGRIDHKIiIjIkBjkEBERkSExyCEiIiJDYpBDREREhsQgh4iIiAyJQQ4REREZEoMcIlLg3FVEZBwMcoiIiMiQGOQQERGRIcU1yKmtrcW8efOQnp6OzMxMLFy4EE1NTSHX+eUvf4nhw4cjKSkJffv2xfnnn48dO3bEs5hERERkQHENcubNm4etW7di1apVePfdd/HZZ5/hqquuCrnOtGnT8Mwzz2D79u344IMPIITAOeecA7fbHc+iEhERkcFIQoi4tDTcvn07xo4dizVr1qCwsBAAsHLlSsyZMwfffvst8vPzI9rOpk2bMGnSJOzevRvDhw8Pu3xDQwMyMjJQX1+P9PT0Th0D0clm653fwTjHJs+D2+q7tzBEdFKJx/U7bpmc0tJSZGZm+gIcAJg5cyZMJhPKy8sj2kZzczOeeeYZDB06FAUFBZrL2O12NDQ0qP6IiIiI4hbkVFVVoV+/fqrnLBYLsrOzUVVVFXLdRx99FKmpqUhNTcX777+PVatWwWq1ai67fPlyZGRk+P70giEiIiI6uUQd5CxZsgSSJIX862xD4Xnz5mHDhg349NNPccopp+CnP/0p2traNJddunQp6uvrfX8HDx7s1L6JiIjIGCzRrnDTTTfhiiuuCLnMsGHDkJeXh6NHj6qed7lcqK2tRV5eXsj1vVmZkSNHori4GFlZWVixYgUuvfTSoGVtNhtsNlu0h0FEREQGF3WQ07dvX/Tt2zfsciUlJairq8O6deswbdo0AMBHH30EWZZRVFQU8f6EEBBCwG63R1tUIiIiOonFrU3OmDFjMHv2bCxatAgVFRX48ssvcd111+GSSy7x9aw6dOgQRo8ejYqKCgDAnj17sHz5cqxbtw4HDhzAV199hYsvvhhJSUmYM2dOvIpKREREBhTXcXJeeOEFjB49GmeddRbmzJmD008/HU888YTvdafTiZ07d6KlpQUAkJiYiM8//xxz5szBiBEjMHfuXKSlpeGrr74KasRMRPHAuauIyDiirq6KRnZ2Nl588UXd14cMGQLlMD35+fl477334lkkIiIiOklw7ioiIiIyJAY5REREZEgMcoiIiMiQGOQQERGRITHIISIiIkNikENERESGxCCHiIiIDIlBDhERERkSgxwiIiIyJAY5REREZEgMcojIR+ruAhARxRCDHCIiIjIkBjlERERkSAxyiIiIyJAY5BAREZEhMcghIiIiQ2KQQ0Q+9bnFAACX4KmBiHo/S3cXgIh6jqnz/oLyt3NRMP2HyO/uwhARdRKDHCLysSUmo+inN3d3MYiIYoI5aSIiIjIkBjlERERkSAxyiIiIyJAY5BAREZEhMcghIiIiQ2KQQ0RERIbEIIeIiIgMiUEOERERGRKDHCIiIjIkBjlERERkSAxyiIiIyJAY5BAREZEhMcghIiIiQzLcLORCCABAQ0NDN5eEiIiIIuW9bnuv47FguCCnsbERAFBQUNDNJSEiIqJoNTY2IiMjIybbkkQsQ6YeQJZlHD58GGlpaZAkKabbbmhoQEFBAQ4ePIj09PSYbrunOVmO9WQ5ToDHalQ8VuM5WY4TUB9rWloaGhsbkZ+fD5MpNq1pDJfJMZlMGDhwYFz3kZ6ebvgvntfJcqwny3ECPFaj4rEaz8lynID/WGOVwfFiw2MiIiIyJAY5REREZEgMcqJgs9mwbNky2Gy27i5K3J0sx3qyHCfAYzUqHqvxnCzHCcT/WA3X8JiIiIgIYCaHiIiIDIpBDhERERkSgxwiIiIyJAY5REREZEgMciL0yCOPYMiQIUhMTERRUREqKiq6u0hR++yzz/DDH/4Q+fn5kCQJb775pup1IQRuvfVW9O/fH0lJSZg5cyZ27dqlWqa2thbz5s1Deno6MjMzsXDhQjQ1NXXhUYS3fPlyTJ8+HWlpaejXrx8uuOAC7Ny5U7VMW1sbrr32WvTp0wepqam46KKLUF1drVrmwIEDOO+885CcnIx+/frh5ptvhsvl6spDCeuxxx7DxIkTfQNplZSU4P333/e9bpTj1HLXXXdBkiTceOONvueMcry33XYbJElS/Y0ePdr3ulGOEwAOHTqEyy67DH369EFSUhImTJiAtWvX+l43ynlpyJAhQZ+pJEm49tprARjrM3W73fjTn/6EoUOHIikpCcOHD8ftt9+umpOqyz5XQWG9/PLLwmq1in/+859i69atYtGiRSIzM1NUV1d3d9Gi8t5774k//OEP4o033hAAxIoVK1Sv33XXXSIjI0O8+eabYuPGjeJHP/qRGDp0qGhtbfUtM3v2bDFp0iRRVlYmPv/8czFixAhx6aWXdvGRhDZr1izxzDPPiC1btojKykoxZ84cMWjQINHU1ORb5uqrrxYFBQVi9erVYu3ataK4uFiceuqpvtddLpcYP368mDlzptiwYYN47733RE5Ojli6dGl3HJKut99+W/z3v/8VX3/9tdi5c6e45ZZbREJCgtiyZYsQwjjHGaiiokIMGTJETJw4Udxwww2+541yvMuWLRPjxo0TR44c8f0dO3bM97pRjrO2tlYMHjxYXHHFFaK8vFzs2bNHfPDBB2L37t2+ZYxyXjp69Kjq81y1apUAID7++GMhhHE+UyGEuOOOO0SfPn3Eu+++K/bu3Stee+01kZqaKh544AHfMl31uTLIicCMGTPEtdde63vsdrtFfn6+WL58eTeWqnMCgxxZlkVeXp645557fM/V1dUJm80mXnrpJSGEENu2bRMAxJo1a3zLvP/++0KSJHHo0KEuK3u0jh49KgCITz/9VAjhOa6EhATx2muv+ZbZvn27ACBKS0uFEJ6A0GQyiaqqKt8yjz32mEhPTxd2u71rDyBKWVlZ4qmnnjLscTY2NoqRI0eKVatWiTPPPNMX5BjpeJctWyYmTZqk+ZqRjvP3v/+9OP3003VfN/J56YYbbhDDhw8Xsiwb6jMVQojzzjtPXHnllarnLrzwQjFv3jwhRNd+rqyuCsPhcGDdunWYOXOm7zmTyYSZM2eitLS0G0sWW3v37kVVVZXqODMyMlBUVOQ7ztLSUmRmZqKwsNC3zMyZM2EymVBeXt7lZY5UfX09ACA7OxsAsG7dOjidTtWxjh49GoMGDVId64QJE5Cbm+tbZtasWWhoaMDWrVu7sPSRc7vdePnll9Hc3IySkhLDHue1116L8847T3VcgPE+1127diE/Px/Dhg3DvHnzcODAAQDGOs63334bhYWFuPjii9GvXz9MmTIFTz75pO91o56XHA4Hnn/+eVx55ZWQJMlQnykAnHrqqVi9ejW+/vprAMDGjRvxxRdf4NxzzwXQtZ+r4SbojLWamhq43W7VFwsAcnNzsWPHjm4qVexVVVUBgOZxel+rqqpCv379VK9bLBZkZ2f7lulpZFnGjTfeiNNOOw3jx48H4DkOq9WKzMxM1bKBx6r1Xnhf60k2b96MkpIStLW1ITU1FStWrMDYsWNRWVlpqOMEgJdffhnr16/HmjVrgl4z0udaVFSEZ599FqNGjcKRI0fw5z//Gd/5znewZcsWQx3nnj178Nhjj2Hx4sW45ZZbsGbNGvz617+G1WrF/PnzDXteevPNN1FXV4crrrgCgLG+uwCwZMkSNDQ0YPTo0TCbzXC73bjjjjswb948AF17vWGQQ4Z27bXXYsuWLfjiiy+6uyhxM2rUKFRWVqK+vh6vv/465s+fj08//bS7ixVzBw8exA033IBVq1YhMTGxu4sTV947XgCYOHEiioqKMHjwYLz66qtISkrqxpLFlizLKCwsxJ133gkAmDJlCrZs2YLHH38c8+fP7+bSxc/TTz+Nc889F/n5+d1dlLh49dVX8cILL+DFF1/EuHHjUFlZiRtvvBH5+fld/rmyuiqMnJwcmM3moFbu1dXVyMvL66ZSxZ73WEIdZ15eHo4ePap63eVyoba2tke+F9dddx3effddfPzxxxg4cKDv+by8PDgcDtTV1amWDzxWrffC+1pPYrVaMWLECEybNg3Lly/HpEmT8MADDxjuONetW4ejR49i6tSpsFgssFgs+PTTT/Hggw/CYrEgNzfXUMerlJmZiVNOOQW7d+821Ofav39/jB07VvXcmDFjfFVzRjwv7d+/H//73//wi1/8wveckT5TALj55puxZMkSXHLJJZgwYQJ+/vOf4ze/+Q2WL18OoGs/VwY5YVitVkybNg2rV6/2PSfLMlavXo2SkpJuLFlsDR06FHl5earjbGhoQHl5ue84S0pKUFdXh3Xr1vmW+eijjyDLMoqKirq8zHqEELjuuuuwYsUKfPTRRxg6dKjq9WnTpiEhIUF1rDt37sSBAwdUx7p582bVj2zVqlVIT08POin3NLIsw263G+44zzrrLGzevBmVlZW+v8LCQsybN8/3v5GOV6mpqQnffPMN+vfvb6jP9bTTTgsa3uHrr7/G4MGDARjrvOT1zDPPoF+/fjjvvPN8zxnpMwWAlpYWmEzq8MJsNkOWZQBd/Ll2ogH1SePll18WNptNPPvss2Lbtm3iqquuEpmZmapW7r1BY2Oj2LBhg9iwYYMAIO677z6xYcMGsX//fiGEp0tfZmameOutt8SmTZvE+eefr9mlb8qUKaK8vFx88cUXYuTIkT2uq+Y111wjMjIyxCeffKLqstnS0uJb5uqrrxaDBg0SH330kVi7dq0oKSkRJSUlvte93TXPOeccUVlZKVauXCn69u3b47prLlmyRHz66adi7969YtOmTWLJkiVCkiTx4YcfCiGMc5x6lL2rhDDO8d50003ik08+EXv37hVffvmlmDlzpsjJyRFHjx4VQhjnOCsqKoTFYhF33HGH2LVrl3jhhRdEcnKyeP75533LGOW8JISnZ+6gQYPE73//+6DXjPKZCiHE/PnzxYABA3xdyN944w2Rk5Mjfve73/mW6arPlUFOhB566CExaNAgYbVaxYwZM0RZWVl3FylqH3/8sQAQ9Dd//nwhhKdb35/+9CeRm5srbDabOOuss8TOnTtV2zh+/Li49NJLRWpqqkhPTxcLFiwQjY2N3XA0+rSOEYB45plnfMu0traKX/3qVyIrK0skJyeLH//4x+LIkSOq7ezbt0+ce+65IikpSeTk5IibbrpJOJ3OLj6a0K688koxePBgYbVaRd++fcVZZ53lC3CEMM5x6gkMcoxyvHPnzhX9+/cXVqtVDBgwQMydO1c1doxRjlMIId555x0xfvx4YbPZxOjRo8UTTzyhet0o5yUhhPjggw8EgKDyC2Gsz7ShoUHccMMNYtCgQSIxMVEMGzZM/OEPf1B1de+qz1USQjEEIREREZFBsE0OERERGRKDHCIiIjIkBjlERERkSAxyiIiIyJAY5BAREZEhMcghIiIiQ2KQQ0RERIbEIIeIiIgMiUEOERERGRKDHCIiIjIkBjlERERkSAxyiIiIyJD+Hya8Qa31cNZKAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_array[0][0])\n",
    "plt.plot(data_array[0][1])\n",
    "plt.plot(data_array[52][0] - data_array[900][0])\n",
    "# plt.plot(data_array[5][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.cuda.device_count())\n",
    "# for i in range(torch.cuda.device_count()):\n",
    "# \tprint(torch.cuda.get_device_name(i))\n",
    "# \tprint(torch.cuda.get_device_properties(i).total_memory / 1e9)\n",
    "# \tprint(torch.cuda.mem_get_info(i)[0] / 1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(272, 270, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.initial_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial linear: torch.Size([1, 270, 120])\n",
      "torch.Size([1, 270, 120])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [640, 320, 1], expected input[1, 270, 120] to have 320 channels, but got 270 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m272\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:7\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubjects\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msubjects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:7\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bm/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bm/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sphere/projects/simon/meg-decoding/models/simpleconv.py:269\u001b[0m, in \u001b[0;36mSimpleConv.forward\u001b[0;34m(self, inputs, batch, subjects)\u001b[0m\n\u001b[1;32m    267\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_path(x)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m length\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# temporal aggregation\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bm/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bm/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bm/lib/python3.8/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/bm/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bm/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bm/lib/python3.8/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bm/lib/python3.8/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [640, 320, 1], expected input[1, 270, 120] to have 320 channels, but got 270 channels instead"
     ]
    }
   ],
   "source": [
    "model(torch.randn(1, 272, 120).to('cuda:7'), subjects = subjects.to('cuda:7'))\n",
    "# model(torch.randn(1, 272, 120), subjects = subjects)\n",
    "# model(torch.randn(1, 272, 120).to('cuda:0'), subjects = subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 270, 120])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "As = torch.randn(1, 270, 120).to('cuda:0')\n",
    "Bs = torch.randn(1, 270, 270).to('cuda:0')\n",
    "# torch.einsum('bij,bjk->bik', As, Bs).shape\n",
    "torch.einsum('bct,bcd->bdt', As, Bs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0413)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(torch.randn(1, 120, 272).to_sparse().values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32640])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1, 120, 272).to_sparse().values().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = np.zeros((100, 272))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fb2c93f9340>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataLoader(fake_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 272])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "values expected sparse tensor layout but got Strided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m DataLoader(fake_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bm/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bm/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/sphere/projects/simon/meg-decoding/models/simpleconv.py:212\u001b[0m, in \u001b[0;36mSimpleConv.forward\u001b[0;34m(self, inputs, batch)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# subjects = batch.subject_index\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# length of any of the inputs\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubsampled_meg_channels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m         mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeg\u001b[39m\u001b[38;5;124m\"\u001b[39m][:\u001b[38;5;241m1\u001b[39m, :, :\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mRuntimeError\u001b[0m: values expected sparse tensor layout but got Strided"
     ]
    }
   ],
   "source": [
    "for batch in DataLoader(fake_data, batch_size=10, shuffle=True):\n",
    "    print(batch.shape)\n",
    "    print(model(batch).shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets = namedtuple(\"Datasets\", \"train valid test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Datasets"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "values expected sparse tensor layout but got Strided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: values expected sparse tensor layout but got Strided"
     ]
    }
   ],
   "source": [
    "batch.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = torch.tensor([18, 22, 10, 22, 23, 21, 18,  9,  0,  7, 12, 22, 19,  3,  9, 12, 13,  4,\n",
    "#         20,  0, 17, 25, 21, 21,  3, 17, 17, 12,  0, 18,  6, 20, 22, 12, 11,  3,\n",
    "#         15, 26,  5,  0, 21,  0, 14,  8,  7,  9, 12, 18, 17, 23,  6,  6,  9, 24,\n",
    "#         14, 19,  9, 23, 17,  6, 21, 20, 21,  3,  4,  3,  8,  5,  8, 11, 15,  4,\n",
    "#         14,  0,  8,  5,  1,  9,  1,  1, 25,  1,  1,  8, 10, 22,  9, 17, 23, 24,\n",
    "#          7,  1, 10,  1, 26,  1, 25, 23, 21,  5,  4,  3, 15, 25, 25, 21, 18, 13,\n",
    "#         15,  8,  4, 25,  4, 14,  4, 14, 19, 10, 18, 17, 25, 10, 10, 23,  1, 12,\n",
    "#          5, 22, 26,  3, 10, 15,  8, 18, 21,  3, 18,  4, 21, 22, 12,  7,  1, 26,\n",
    "#         21,  3, 16, 18,  3, 17, 17, 12, 18, 12,  7,  6, 16,  9, 24, 18,  2,  3,\n",
    "#          8,  1, 20,  3, 21,  6,  3, 13,  6,  9,  4,  9, 12,  9, 16,  6,  5, 17,\n",
    "#         14, 25, 25,  5,  2, 13,  3, 17, 25, 21, 19, 17, 18,  1, 18,  6, 24, 24,\n",
    "#          0,  7, 23,  1,  6,  1, 23,  1,  7, 21, 25, 23, 12, 13,  9, 11, 26,  5,\n",
    "#         18,  8,  5, 12,  3, 24,  0, 17, 18, 17, 19,  8,  5, 18,  3,  5, 16, 15,\n",
    "#         24, 25, 26, 22, 11,  7,  0, 15, 14,  0, 13,  9,  1, 16, 22,  7, 10,  1,\n",
    "#         24,  3,  4, 25]) # 256"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
